{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YCB2Jm8Wt1KU",
    "outputId": "96cccced-27bf-4a2a-baae-67fd04a56a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 18 08:50:18 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   76C    P0    33W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8cSsnY4_h_u",
    "outputId": "7b3b6ed0-cedd-428e-d1a5-7c96d9c96c1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8kB7zY9__AZ",
    "outputId": "3e7baa07-209a-4a6a-ec09-2a5ef1a46516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Deep Learning\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NdciJe00GQQL"
   },
   "outputs": [],
   "source": [
    "! pip install -q tensorflow_datasets\n",
    "! pip install -q tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xRa5RF-UA_nY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import regex as re\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "import logging\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_text as tf_text\n",
    "import tensorflow as tf\n",
    "\n",
    "import nltk.translate.bleu_score as bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zVxLgVJ8Pnuv"
   },
   "outputs": [],
   "source": [
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rp3uFQKxafK",
    "outputId": "9d4373a8-01e0-4d93-cd31-3ed8db7996b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.en',\n",
       " 'test.vi',\n",
       " 'train.en',\n",
       " 'validation.vi',\n",
       " 'train.vi',\n",
       " 'validation.en']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PcgYKDx9Awvv"
   },
   "outputs": [],
   "source": [
    "def create_dataset(src_file, trg_file):\n",
    "    with open(src_file, 'r', encoding='utf-8') as f:\n",
    "        list_src = f.readlines()\n",
    "    \n",
    "    with open(trg_file, 'r', encoding='utf-8') as f:\n",
    "        list_trg = f.readlines()\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list_src, list_trg))\n",
    "    dataset = dataset.prefetch(0)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "G_np19olmPh4"
   },
   "outputs": [],
   "source": [
    "# tạo dataset từ các file\n",
    "train_examples = create_dataset(\"data/train.en\", \"data/train.vi\")\n",
    "validation_examples = create_dataset(\"data/validation.en\", \"data/validation.vi\")\n",
    "test_examples = create_dataset(\"data/test.en\", \"data/test.vi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CnMwBiEZ72qt"
   },
   "outputs": [],
   "source": [
    "model_name = 'translate_en_vi_converter'\n",
    "tokenizers = tf.saved_model.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qluUMa6gmsvo",
    "outputId": "6c098524-0231-41c3-e797-4655012613f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rachel pike : the science behind a climate headline\n",
      "\n",
      "in 4 minutes , atmospheric chemist rachel pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .\n",
      "\n",
      "i 'd like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\n",
      "\n",
      "\n",
      "khoa học đằng sau một tiêu đề về khí hậu\n",
      "\n",
      "trong 4 phút , chuyên gia hoá học khí quyển rachel pike giới thiệu sơ lược về những nỗ lực khoa học miệt mài đằng sau những tiêu đề táo bạo về biến đổi khí hậu , cùng với đoàn nghiên cứu của mình -- hàng ngàn người đã cống hiến cho dự án này -- một chuyến bay mạo hiểm qua rừng già để tìm kiếm thông tin về một phân tử then chốt .\n",
      "\n",
      "tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for en_examples, vi_examples in train_examples.batch(3).take(1):\n",
    "    for en in en_examples.numpy():\n",
    "        print(en.decode('utf-8'))\n",
    "\n",
    "    print()\n",
    "\n",
    "    for vi in vi_examples.numpy():\n",
    "        print(vi.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czKSQ3aKYOeO",
    "outputId": "5945fc65-1323-49fe-a0d3-3b085158c716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 449, 217, 1227, 260, 162, 500, 265, 189, 515, 811, 3]\n",
      "[2, 172, 23, 690, 15, 791, 302, 324, 217, 515, 1065, 182, 3198, 54, 582, 1991, 241, 1127, 1089, 1354, 189, 165, 1236, 415, 449, 217, 3274, 2851, 1227, 260, 165, 500, 265, 1582, 1086, 189, 454, 295, 515, 811, 15, 268, 179, 1398, 430, 370, 166, 242, 16, 16, 319, 1012, 171, 176, 2200, 1620, 181, 483, 609, 175, 16, 16, 162, 958, 530, 1440, 799, 287, 1121, 1056, 188, 304, 613, 310, 289, 189, 162, 424, 503, 2580, 1402, 17, 3]\n",
      "[2, 160, 235, 181, 173, 169, 224, 189, 180, 784, 273, 166, 165, 1236, 415, 449, 217, 176, 1142, 285, 183, 231, 173, 1001, 3013, 169, 347, 208, 216, 632, 17, 3]\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizers.vi.tokenize(vi_examples)\n",
    "\n",
    "for row in encoded.to_list():\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JA4kszIMYnag",
    "outputId": "d424c4af-179f-4b75-e9d2-1fb34815f696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "khoa học đằng sau một tiêu đề về khí hậu\n",
      "trong 4 phút , chuyên gia hoá học khí quyển rachel pike giới thiệu sơ lược về những nỗ lực khoa học miệt mài đằng sau những tiêu đề táo bạo về biến đổi khí hậu , cùng với đoàn nghiên cứu của mình - - hàng ngàn người đã cống hiến cho dự án này - - một chuyến bay mạo hiểm qua rừng già để tìm kiếm thông tin về một phân tử then chốt .\n",
      "tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .\n"
     ]
    }
   ],
   "source": [
    "round_trip = tokenizers.vi.detokenize(encoded)\n",
    "for line in round_trip.numpy():\n",
    "  print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DLRPQlISpJBZ"
   },
   "outputs": [],
   "source": [
    "def tokenize_pairs(en, vi):\n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    en = en.to_tensor()\n",
    "\n",
    "    vi = tokenizers.vi.tokenize(vi)\n",
    "    vi = vi.to_tensor()\n",
    "    \n",
    "    return en, vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "F6lhKtLRsUQY"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XXWZk_SeIOHh"
   },
   "outputs": [],
   "source": [
    "def make_batches(ds):\n",
    "    return (\n",
    "        ds\n",
    "        .cache()\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "train_batches = make_batches(train_examples)\n",
    "validation_batches = make_batches(validation_examples)\n",
    "test_batches = make_batches(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Rt-8dD25ClEZ"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Lps8pZRaC0Ua"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
    "\n",
    "  # dùng hàm sin cho vị trí chẵn\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "  # dùng hàm cos cho vị trí lẻ\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-zpp84U4C5AB"
   },
   "outputs": [],
   "source": [
    "# hàm tạo mask cho câu\n",
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "BOvduMJYC8xj"
   },
   "outputs": [],
   "source": [
    "# hàm tạo mask để che đi phần chưa được dịch đến\n",
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-BdNmUFrDAzx"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  # tính trọng số attention\n",
    "  # đầu vào bao gồm q(query), k(key), v(value)\n",
    "  # tính toán theo công thức\n",
    "  \n",
    "  \"\"\"\n",
    "  Các tham số\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: (..., seq_len_q, seq_len_k). Mặc định là None.\n",
    "  \"\"\"\n",
    "\n",
    "  # nhân q với k\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # chia cho sqrt(d_k)\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # thêm mask nếu có\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "  # dùng hàm softmax để chuẩn hóa về dạng xác suất\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ExN9hgnqDZ6z"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    # chia d_model thành các head, mỗi head có số chiều là depth\n",
    "    # chuyển tensor theo shape là (batch_size, num_heads, seq_len, depth)\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "\n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "on26pLaYDd34"
   },
   "outputs": [],
   "source": [
    "# fully connected neural network\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yvUl9TudDi0m"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xRAzl7MoDnvL"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "CIzcNOgUDsS_"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "\n",
    "    # embedding đầu vào và thực hiện positional encoding\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "6EeZKM0rDwMz"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "\n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "\n",
    "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Rx7m8QY7D1P1"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.tokenizer = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                             input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inp, tar, training, enc_padding_mask,\n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.tokenizer(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "gtMWUOe_D5k_"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 256\n",
    "dff = 1024\n",
    "num_heads = 4\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "qolvwMTtD72O"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=30000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qmYVhGI5D8qb"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "fDMsCm1xD-Sx",
    "outputId": "38d67d00-a79d-403f-ddbe-e14ff783bf3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(80000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Sv_PpN0NEBuf"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, label_smoothing=0.1, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ClXDQkJ9EDqe"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  real_ = tf.one_hot(tf.cast(real, tf.int64), tokenizers.vi.get_vocab_size())\n",
    "\n",
    "  loss_ = loss_object(real_, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9VopW9uaEEWf"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "\n",
    "validation_loss = tf.keras.metrics.Mean(name='validation_loss')\n",
    "validation_accuracy = tf.keras.metrics.Mean(name='validation_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "9iOcJJBmEHgJ"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=tokenizers.en.get_vocab_size(),\n",
    "    target_vocab_size=tokenizers.vi.get_vocab_size(),\n",
    "    pe_input=1000,\n",
    "    pe_target=1000,\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "YMq3YJ1FEJgz"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Tạo padding mask cho encoder\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "  # Dùng trong tầng attention thứ hai trong decoder\n",
    "  # Mask này để che đi output của encoder\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "  # Tạo mask cho tầng attention thứ nhất của decoder\n",
    "  # Dùng để padding và che các từ chưa được dịch từ đầu vào của decoder\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egyYBrmFELrQ",
    "outputId": "f8debcf2-9ee8-4566-ca62-b2998f4f745e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "\n",
    "\n",
    "ckpt.restore(\"./checkpoints/train/ckpt-22\")\n",
    "print('Best checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "tmA2v2V-ENlK"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Pb_bPEnWEQTt"
   },
   "outputs": [],
   "source": [
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1] # đầu vào cho decoder\n",
    "  tar_real = tar[:, 1:] # đầu ra cho mô hình\n",
    "\n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp,\n",
    "                                 True,\n",
    "                                 enc_padding_mask,\n",
    "                                 combined_mask,\n",
    "                                 dec_padding_mask)\n",
    "    # tính lỗi\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "  \n",
    "    \n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(accuracy_function(tar_real, predictions))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "nqEKQF7lETEW",
    "outputId": "030cafb5-3c2c-45b6-fd69-b31923c3e7f3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"for epoch in range(EPOCHS):\\n  start = time.time()\\n\\n  train_loss.reset_states()\\n  train_accuracy.reset_states()\\n\\n  # inp -> english, tar -> vietnamese\\n  for (batch, (inp, tar)) in enumerate(train_batches):\\n    train_step(inp, tar)\\n    if batch % 200 == 0:\\n      print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\\n  \\n  validation_loss.reset_states()\\n  validation_accuracy.reset_states()\\n\\n  for (batch, (inp, tar)) in enumerate(validation_batches):\\n    tar_inp = tar[:, :-1]\\n    tar_real = tar[:, 1:]\\n\\n    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\\n\\n    predictions, _ = transformer(inp, tar_inp,\\n                                 True,\\n                                 enc_padding_mask,\\n                                 combined_mask,\\n                                 dec_padding_mask)\\n    val_loss = loss_function(tar_real, predictions)\\n\\n    validation_loss(val_loss)\\n    validation_accuracy(accuracy_function(tar_real, predictions))\\n\\n  if (epoch + 1) % 1 == 0:\\n    ckpt_save_path = ckpt_manager.save()\\n    print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\\n  \\n\\n  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\\n\\n  print(f'Validation loss: {validation_loss.result():.4f} Validation accuracy {validation_accuracy.result():.4f}')\\n\\n  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\\n  \""
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "\n",
    "  # inp -> english, tar -> vietnamese\n",
    "  for (batch, (inp, tar)) in enumerate(train_batches):\n",
    "    train_step(inp, tar)\n",
    "    if batch % 200 == 0:\n",
    "      print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "  \n",
    "  validation_loss.reset_states()\n",
    "  validation_accuracy.reset_states()\n",
    "\n",
    "  for (batch, (inp, tar)) in enumerate(validation_batches):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    predictions, _ = transformer(inp, tar_inp,\n",
    "                                 True,\n",
    "                                 enc_padding_mask,\n",
    "                                 combined_mask,\n",
    "                                 dec_padding_mask)\n",
    "    val_loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    validation_loss(val_loss)\n",
    "    validation_accuracy(accuracy_function(tar_real, predictions))\n",
    "\n",
    "  if (epoch + 1) % 1 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
    "  \n",
    "\n",
    "  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "  print(f'Validation loss: {validation_loss.result():.4f} Validation accuracy {validation_accuracy.result():.4f}')\n",
    "\n",
    "  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Upm32dH4udDL"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=40):\n",
    "  # đầu vào là tiếng anh thêm các token start và end\n",
    "  sentence = tf.convert_to_tensor([sentence])\n",
    "  sentence = tokenizers.en.tokenize(sentence).to_tensor()\n",
    "\n",
    "  encoder_input = sentence\n",
    "\n",
    "  # để mô hình dự đoán là câu tiếng việt, cần đưa vào decoder token start vietnamese\n",
    "  start, end = tokenizers.vi.tokenize([''])[0]\n",
    "  output = tf.convert_to_tensor([start])\n",
    "  output = tf.expand_dims(output, 0)\n",
    "\n",
    "  for i in range(max_length):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "\n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input,\n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "\n",
    "    # mỗi bước tính toán lấy từ cuối cùng của câu\n",
    "    predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "    # thêm từ cuối cùng vào tâp các từ output đã tính để đưa vào lần lặp tiếp theo\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    # dừng khi kết quả nhận được là end token\n",
    "    if predicted_id == end:\n",
    "      break\n",
    "  \n",
    "  # output.shape (1, tokens)\n",
    "  text = tokenizers.vi.detokenize(output)[0]  # shape: ()\n",
    "\n",
    "  tokens = tokenizers.vi.lookup(output)[0]\n",
    "\n",
    "  return text, tokens, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "M2TBQ9yqugUW"
   },
   "outputs": [],
   "source": [
    "def print_translation(sentence, tokens, google_translate):\n",
    "  print(f'{\"Input:\":20s}: {sentence}')\n",
    "  print(f'{\"Prediction\":20s}: {tokens.numpy().decode(\"utf-8\")}')\n",
    "  print(f'{\"Google translate\":20s}: {google_translate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJQIynQJukX0",
    "outputId": "c909d394-90fb-4297-d2ff-c2d9c781cb88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:              : i'm the king of the world. \n",
      "Prediction          : tôi là vị vua của thế giới .\n",
      "Google translate    : tôi là vua của thế giới.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"i'm the king of the world. \"\n",
    "google_translate = \"tôi là vua của thế giới.\"\n",
    "\n",
    "translated_text, translated_tokens, attention_weights = evaluate(sentence)\n",
    "print_translation(sentence, translated_text, google_translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ofGKCcrK0GmV"
   },
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "def bleu_score(dataset):\n",
    "  reference_list = []\n",
    "  candidate_list = []\n",
    "\n",
    "  for en_examples, vi_examples in dataset:\n",
    "    en_str = en_examples.numpy().decode('utf-8')\n",
    "    \n",
    "    vi_str = vi_examples.numpy().decode('utf-8')\n",
    "\n",
    "    reference_list.append([vi_str.split(' ')])\n",
    "  \n",
    "    pre_vi_str, _, _ = evaluate(en_str)\n",
    "    pre_vi_str = pre_vi_str.numpy().decode('utf-8')\n",
    "  \n",
    "    candidate_list.append(pre_vi_str.split(' '))\n",
    "    \n",
    "  return bleu.corpus_bleu(reference_list, candidate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_k2Je2tAyeiS",
    "outputId": "3f40d61e-cb2d-4a19-b77b-7602be9542a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation BLEU score: 0.2143818975214525\n",
      "Test BLEU score: 0.22122029168371446\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation BLEU score:\", bleu_score(validation_examples))\n",
    "print(\"Test BLEU score:\", bleu_score(test_examples))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "machine_translation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
