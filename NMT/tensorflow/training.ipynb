{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YCB2Jm8Wt1KU",
    "outputId": "5a966ac2-daaf-4528-b4dc-81d98fcd6557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8cSsnY4_h_u",
    "outputId": "d6a2639b-7d43-4e5e-dedb-422831aa554a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cal_bleu_score.ipynb  demo.ipynb     loss.ipynb\r\n",
      "checkpoints\t      DL_Report.pdf  training.ipynb\r\n",
      "data\t\t      DL_Slide.pptx  translate_en_vi_converter\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8kB7zY9__AZ",
    "outputId": "70913579-8f72-4aea-dbf0-4a357fd474fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Deep Learning\n"
     ]
    }
   ],
   "source": [
    "# cd drive/MyDrive/Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdciJe00GQQL",
    "outputId": "f4266524-1cec-4b89-a190-ecb828eab282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n"
     ]
    }
   ],
   "source": [
    "! pip3 install -q tensorflow_datasets\n",
    "! pip3 install -q tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xRa5RF-UA_nY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import regex as re\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "import logging\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_text as tf_text\n",
    "import tensorflow as tf\n",
    "\n",
    "import nltk.translate.bleu_score as bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zVxLgVJ8Pnuv"
   },
   "outputs": [],
   "source": [
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rp3uFQKxafK",
    "outputId": "5c80c094-48c8-46df-a0b1-10319d3fa45b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.en',\n",
       " 'test.vi',\n",
       " 'train.en',\n",
       " 'validation.vi',\n",
       " 'train.vi',\n",
       " 'validation.en']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PcgYKDx9Awvv"
   },
   "outputs": [],
   "source": [
    "def create_dataset(src_file, trg_file):\n",
    "    with open(src_file, 'r', encoding='utf-8') as f:\n",
    "        list_src = f.readlines()\n",
    "    \n",
    "    with open(trg_file, 'r', encoding='utf-8') as f:\n",
    "        list_trg = f.readlines()\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list_src, list_trg))\n",
    "    dataset = dataset.prefetch(0)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "G_np19olmPh4"
   },
   "outputs": [],
   "source": [
    "# tạo dataset từ các file\n",
    "train_examples = create_dataset(\"data/train.en\", \"data/train.vi\")\n",
    "validation_examples = create_dataset(\"data/validation.en\", \"data/validation.vi\")\n",
    "test_examples = create_dataset(\"data/test.en\", \"data/test.vi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CnMwBiEZ72qt"
   },
   "outputs": [],
   "source": [
    "model_name = 'translate_en_vi_converter'\n",
    "tokenizers = tf.saved_model.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qluUMa6gmsvo",
    "outputId": "63045723-1b42-40c1-af58-34295a2bdd8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rachel pike : the science behind a climate headline\n",
      "\n",
      "in 4 minutes , atmospheric chemist rachel pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .\n",
      "\n",
      "i 'd like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\n",
      "\n",
      "\n",
      "khoa học đằng sau một tiêu đề về khí hậu\n",
      "\n",
      "trong 4 phút , chuyên gia hoá học khí quyển rachel pike giới thiệu sơ lược về những nỗ lực khoa học miệt mài đằng sau những tiêu đề táo bạo về biến đổi khí hậu , cùng với đoàn nghiên cứu của mình -- hàng ngàn người đã cống hiến cho dự án này -- một chuyến bay mạo hiểm qua rừng già để tìm kiếm thông tin về một phân tử then chốt .\n",
      "\n",
      "tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for en_examples, vi_examples in train_examples.batch(3).take(1):\n",
    "    for en in en_examples.numpy():\n",
    "        print(en.decode('utf-8'))\n",
    "\n",
    "    print()\n",
    "\n",
    "    for vi in vi_examples.numpy():\n",
    "        print(vi.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czKSQ3aKYOeO",
    "outputId": "35fb5c04-30db-4038-b001-dcbe93741bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 449, 217, 1227, 260, 162, 500, 265, 189, 515, 811, 3]\n",
      "[2, 172, 23, 690, 15, 791, 302, 324, 217, 515, 1065, 182, 3198, 54, 582, 1991, 241, 1127, 1089, 1354, 189, 165, 1236, 415, 449, 217, 3274, 2851, 1227, 260, 165, 500, 265, 1582, 1086, 189, 454, 295, 515, 811, 15, 268, 179, 1398, 430, 370, 166, 242, 16, 16, 319, 1012, 171, 176, 2200, 1620, 181, 483, 609, 175, 16, 16, 162, 958, 530, 1440, 799, 287, 1121, 1056, 188, 304, 613, 310, 289, 189, 162, 424, 503, 2580, 1402, 17, 3]\n",
      "[2, 160, 235, 181, 173, 169, 224, 189, 180, 784, 273, 166, 165, 1236, 415, 449, 217, 176, 1142, 285, 183, 231, 173, 1001, 3013, 169, 347, 208, 216, 632, 17, 3]\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizers.vi.tokenize(vi_examples)\n",
    "\n",
    "for row in encoded.to_list():\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JA4kszIMYnag",
    "outputId": "3dba4883-36d1-4079-8f7a-fa2d4ae42b12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "khoa học đằng sau một tiêu đề về khí hậu\n",
      "trong 4 phút , chuyên gia hoá học khí quyển rachel pike giới thiệu sơ lược về những nỗ lực khoa học miệt mài đằng sau những tiêu đề táo bạo về biến đổi khí hậu , cùng với đoàn nghiên cứu của mình - - hàng ngàn người đã cống hiến cho dự án này - - một chuyến bay mạo hiểm qua rừng già để tìm kiếm thông tin về một phân tử then chốt .\n",
      "tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .\n"
     ]
    }
   ],
   "source": [
    "round_trip = tokenizers.vi.detokenize(encoded)\n",
    "for line in round_trip.numpy():\n",
    "  print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DLRPQlISpJBZ"
   },
   "outputs": [],
   "source": [
    "def tokenize_pairs(en, vi):\n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    en = en.to_tensor()\n",
    "\n",
    "    vi = tokenizers.vi.tokenize(vi)\n",
    "    vi = vi.to_tensor()\n",
    "    \n",
    "    return en, vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "F6lhKtLRsUQY"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XXWZk_SeIOHh"
   },
   "outputs": [],
   "source": [
    "def make_batches(ds):\n",
    "    return (\n",
    "        ds\n",
    "        .cache()\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "train_batches = make_batches(train_examples)\n",
    "validation_batches = make_batches(validation_examples)\n",
    "test_batches = make_batches(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Rt-8dD25ClEZ"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Lps8pZRaC0Ua"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
    "\n",
    "  # dùng hàm sin cho vị trí chẵn\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "  # dùng hàm cos cho vị trí lẻ\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-zpp84U4C5AB"
   },
   "outputs": [],
   "source": [
    "# hàm tạo mask cho câu\n",
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "BOvduMJYC8xj"
   },
   "outputs": [],
   "source": [
    "# hàm tạo mask để che đi phần chưa được dịch đến\n",
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-BdNmUFrDAzx"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  # tính trọng số attention\n",
    "  # đầu vào bao gồm q(query), k(key), v(value)\n",
    "  # tính toán theo công thức\n",
    "  \n",
    "  \"\"\"\n",
    "  Các tham số\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: (..., seq_len_q, seq_len_k). Mặc định là None.\n",
    "  \"\"\"\n",
    "\n",
    "  # nhân q với k\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # chia cho sqrt(d_k)\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # thêm mask nếu có\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "  # dùng hàm softmax để chuẩn hóa về dạng xác suất\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ExN9hgnqDZ6z"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    # chia d_model thành các head, mỗi head có số chiều là depth\n",
    "    # chuyển tensor theo shape là (batch_size, num_heads, seq_len, depth)\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "\n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "on26pLaYDd34"
   },
   "outputs": [],
   "source": [
    "# fully connected neural network\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yvUl9TudDi0m"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xRAzl7MoDnvL"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "CIzcNOgUDsS_"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "\n",
    "    # embedding đầu vào và thực hiện positional encoding\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "6EeZKM0rDwMz"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "  def call(self, x, enc_output, training,\n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "\n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "\n",
    "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Rx7m8QY7D1P1"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.tokenizer = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                             input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inp, tar, training, enc_padding_mask,\n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.tokenizer(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "gtMWUOe_D5k_"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 256\n",
    "dff = 1024\n",
    "num_heads = 4\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "qolvwMTtD72O"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=30000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qmYVhGI5D8qb"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "fDMsCm1xD-Sx",
    "outputId": "c9c6d1dc-562d-47d0-dcd1-d182b4b373f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEGCAYAAACzYDhlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV1fn48c+ThLCTAAlbAiRAWIKCQERQUBGVRZCq+BO6uFRrrVC12gW7uFD91l3rrlXrUhUotZVNEWUREYEAghIIhD2sIUDYCUme3x/3YK9pNiCTuTd53q/XfTFz5syZ55KbPPfMnJkjqooxxhjjpQi/AzDGGFP9WbIxxhjjOUs2xhhjPGfJxhhjjOcs2RhjjPFclN8BhKK4uDhNSkryOwxjjAkrS5cu3aOq8SVts2RTgqSkJNLT0/0OwxhjwoqIbC5tm51GM8YY4zlLNsYYYzxnycYYY4znLNkYY4zxnCUbY4wxnrNkY4wxxnOWbIwxxnjOko0xxeQXFDFh8Rb2Hs73OxRjqg1LNsYU88aCjYz74BsGP/M563Yd9DscY6oFSzbGBNl98BjPfbaOuAbRFClc/eKXzMnc7XdYxoQ9SzbGBHn840zyC4v4523nM2XsBbRuUo+b31zC619sxGa1Neb0eZpsRGSwiGSKSJaIjCthe20Rmei2LxKRpKBt97ryTBEZVF6bIvK6iKwQkZUiMllEGrjyG0UkR0S+dq9bvHzPJnytzN7PP5dm89MLkkmOq0+r2LpM/kVfLkttzp+nZfD7f39DfkGR32EaE5Y8SzYiEgm8AAwBUoHRIpJarNrNwD5V7QA8DTzq9k0FRgFdgcHAiyISWU6bv1LV7qraDdgCjA06zkRVPce9XvPi/Zrwpqo8ODWDuAbRjL2kw3fl9aKjeOlHvRgzoD3vL97Kj19fxO6Dx3yM1Jjw5GXPpjeQpaobVDUfmACMKFZnBPCWW54MDBQRceUTVPW4qm4Eslx7pbapqgcA3P51ATvnYSpsyortLN28j98M6kTDOrW+ty0iQvjNoM48c905rMzez/DnvmDp5r0+RWpMePIy2SQAW4PWs11ZiXVUtQDIA5qWsW+ZbYrI34GdQGfguaB61wSdXmtdUrAicquIpItIek5OToXfpAl/R/ILeOSjNZyV0IiRvUr8eADwgx4JfPCLC6gdFcl1r3zFW19usus4xlRQtRogoKo3Aa2A1cB1rngqkOROr83ivz2p4vu+qqppqpoWH1/i3D+mmnp53gZ25B3j/uFdiYyQMuumtmrE1LH9uKhjPPdPWcXdk1ZwNL+wiiI1Jnx5mWy2AcFfExNdWYl1RCQKiAFyy9i33DZVtZDA6bVr3Hquqh53m18Dep32OzLVTva+I7wybz3Du7fi3KQmFdonpl4t/nZ9Gvdc1pH/fL2Nq15cQNZuux/HmLJ4mWyWACkikiwi0QQu+E8pVmcKcINbHgnM1sB5iSnAKDdaLRlIARaX1qYEdIDvrtlcCaxx6y2DjnclgV6PMQA88tEaRGDckM6ntF9EhPDLgSm8eVNvdh88zvDnFjBxyRY7rWZMKTybFlpVC0RkLDATiATeUNVVIjIeSFfVKcDrwDsikgXsJZA8cPUmARlAATDG9Vgopc0I4C0RaQQIsAL4hQvlDhG50rWzF7jRq/dswsvijXuZtnIHdw5MISG27mm1cVHHeD66sz+/mvg1v/vXN8xft4f/u/psGhUbZGBMTSf2Tex/paWlaXp6ut9hGA8VFilXPv8Few/nM/uei6kbHXnG7b08bz1PzVpLq9g6PDuqBz3aNK6kaI0JDyKyVFXTStpWrQYIGFNR/0zfyqrtB7h3aJczTjQAkRHCmAEdmPTzPhQVwbUvL+SluespLLIvc8aAJRtTAx04doLHZ2aS1rYxw7u1LH+HU9CrbRNm3Nmfy7s259GP1zDq1YVszj1cqccwJhxZsjE1znOfrWPvkXzuH96VwHiSyhVTtxYv/LAnT/2/7qzZeZDBz8znna822+ABU6NZsjE1yoacQ7z55Sau7ZXI2Ykxnh1HRLi6ZyKf/OpC0pIa86f/fMv1byxmR95Rz45pTCizZGNqlIenr6Z2VCS/HtSpSo7XMqYub/+0N3/+wVmkb9rH5U9/zgfLsq2XY2ocSzamxpibuZvP1uzml5d0oFnDOlV2XBHhJ33a8vFd/enUvCF3T1rBjX9fwta9R6osBmP8ZsnG1AgnCov487QMkprW48YLknyJoW3T+kz8eV/uH57Kkk17ufzpz3lt/gYbsWZqBEs2pkZ4Z+Fm1ucc5o9XpFI76syHOp+uyAjhpguSmXX3RfRt35SHpq/mqhcXkLH9gG8xGVMVLNmYam/v4Xye+XQt/VPiGNilmd/hAJAQW5fXb0jjudE92L7/KMOf/4JHPlpjD/U01ZYlG1PtPTUrk8P5hfxpWKonQ51Pl4gwvHsrPr37Iq7pmcDL89Zz6VPz+PjbnTaAwFQ7lmxMtbZ6xwHeW7SFn/RpS8fmDf0Op0Sx9aJ5bGR3Jtzah4Z1orjtH0u5/o3FrM855HdoxlQaSzam2lJVxk/NoFHdWtx1aYrf4ZSrT7umTPtlPx4YnsrXW/cz+JnP+ctHqzl0vMDv0Iw5Y5ZsTLU1c9VOFm7I5Z7LOhJbL9rvcCokKjKCGy9IZs6vL+YH5yTwyrwNDHxyLh9+vc1OrZmwZsnGVEvHThTy8IzVdGrekNG92/gdzimLa1Cbx6/tzge3n0+zhnW4c8LXXPvyQpZv2ed3aMacFks2plp6/YuNbN17lPuGpxIVGb4f855tGvOfMRfwyNVnsyn3CFe9+CVj31vGlly7IdSEl/D9LTSmFLsOHOOFOVlcntqcCzrE+R3OGYuMEEb1bsO831zMHQNT+HT1LgY+NZeHpmWQd+SE3+EZUyGWbEy18+jHaygoVP5wRRe/Q6lU9WtHcfdlHZn76wFc1SOB1xds5MLH5/Da/A0cO2H355jQZsnGVCvLt+zjg2XbuLl/Mm2b1vc7HE+0iKnDYyO7M+OO/nRLjOGh6asZ8MRc3l+8hROFRX6HZ0yJPE02IjJYRDJFJEtExpWwvbaITHTbF4lIUtC2e115pogMKq9NEXldRFaIyEoRmSwiDco7hqleioqUB6dmEN+wNmMGdPA7HM91admId24+j3dvOY/mjepw7wffcOlT8/j38mx73poJOZ4lGxGJBF4AhgCpwGgRSS1W7WZgn6p2AJ4GHnX7pgKjgK7AYOBFEYksp81fqWp3Ve0GbAHGlnUMU/18uGIbX2/dz28HdaJB7Si/w6kyF3SI49+3n8/rN6RRLzqKX01cwZC/fs7H3+6w4dImZHjZs+kNZKnqBlXNByYAI4rVGQG85ZYnAwMl8DyREcAEVT2uqhuBLNdeqW2q6gEAt39dQMs5hqlGDh8v4JGP1tAtMYZreib6HU6VExEGdmnO9F/24/kf9qCgSLntH8u48vkFfJqxy5KO8Z2XySYB2Bq0nu3KSqyjqgVAHtC0jH3LbFNE/g7sBDoDz5VzDFONvDR3PbsOHOf+4V2JiKi53yUiIoRh3VrxyV0X8sS13dl/NJ9b3k5n6LNfMH3lDju9ZnxTrQYIqOpNQCtgNXDdqewrIreKSLqIpOfk5HgSn/HG1r1HeHX+Bn5wTit6tW3sdzghISoygpG9Epl9z8U8eW13jhcUMua9ZVz+9Dw+WJZNgQ0kMFXMy2SzDWgdtJ7oykqsIyJRQAyQW8a+5bapqoUETq9dU84xKLbfq6qapqpp8fHxFX6Txn//N2M1kSL8bkhnv0MJObUiI7imVyKzfnURz/+wB7UiI7h70goGPDmX9xZt4XiBDZk2VcPLZLMESBGRZBGJJnDBf0qxOlOAG9zySGC2Bk4uTwFGuZFkyUAKsLi0NiWgA3x3zeZKYE05xzDVwML1uXz07U5uv7g9LWPq+h1OyIp0p9c+urM/r12fRpN60fz+399w0WNzeW3+BnvYp/GcZ0N2VLVARMYCM4FI4A1VXSUi44F0VZ0CvA68IyJZwF4CyQNXbxKQARQAY1yPhVLajADeEpFGgAArgF+4UEo8hgl/hUXKg1NXkRBbl59d2M7vcMKCiHBpanMGdmnGF1l7eG52Fg9NX81fP13H6PPacOP5SbSKtaRtKp/Yl/z/lZaWpunp6X6HYcrx7qLN/OHf3/LCD3tyRbeWfocTtlZs3c/f5m9gxjc7iBBhWLeW3NK/HWclxPgdmgkzIrJUVdNK2lZzbkYw1UrekRM8MTOT3slNGHp2C7/DCWvdW8fy/A97snXvEf6+YBMTl2zhP19vp2+7ptx6YTsu6hhfo0f4mcpRrUajmZrjr5+tY//RE9w/PLSmeg5nrZvU477hqXx570DuHdKZjXsOc9ObS7js6Xm89eUmDh6zh36a02en0Upgp9FCW9buQwx+5nOuTWvNX64+2+9wqq38giKmf7OdNxdsYkV2HvWjI7mmVyLX921Lh2ahOcW28ZedRjPVykPTM6hbK5J7Lu/odyjVWnRUBFf1SOSqHol8vXU/by/cxITFW3l74WYu6NCUn/RJ4tIuzcJ6viBTdSzZmLAyZ81u5mbm8McruhDXoLbf4dQY57SO5ZzW5/CHoV2YmL6Vd7/awm3/WEqrmDr8qE9bru2VSLNGdfwO04QwO41WAjuNFpryC4oY/MznAHx814VER9k3ar8UFBbx2ZrdvL1wEwuycomMEC7p3IxR57bmoo7x1tupoew0mqkW3l64iQ17DvP3G8+1ROOzqMgIBnVtwaCuLdi45zATl2xl8tJsZmXsokWjOlyblsj/S2tN6yb1/A7VhAjr2ZTAejahZ8+h4wx4fC69khrz5k29/Q7HlOBEYRGfrd7NhCVbmLc28HzBfh3iGHVuGy5LbW5fEGoA69mYsPfkJ2s5eqKQP15RfEokEypqRUYw+KwWDD6rBdv2H+Wf6VuZtGQrY95bRpP60VzZvRVX90zg7IQYG65eA1nPpgTWswktq7bnMey5L7jp/GTuG27JJpwUFimfr8v57hRbfkERHZo14OqeCVzVI8GeZ1fNlNWzsWRTAks2oUNVue7Vr8jafYg591xMTL1afodkTlPe0RPM+GYH/1qaTfrmfYjABe3juLpnAoO6tqB+DZpdtbqy02gmbM34ZieLN+7l4avOskQT5mLq1mJ07zaM7t2GzbmH+WDZNj5Yns3dk1ZQL/pbLk9tzvDureifEm/Xd6oh69mUwHo2oeHYiUIGPjmPhnWimH5HfyLt+VzVjqqSvnkfHyzLZsY3O8k7eoJGdaIYfFYLhnVrxfntm9ow6jBiPRsTlv72+Qa27T/K+z/rY4mmmhIRzk1qwrlJTXjwyrNYkLWHqSu3M+ObnUxKz6ZJ/WiGuMTTO7mJfQ7CmCUbE5J25B3lxbnrGXJWC/q2b+p3OKYKREdFMKBzMwZ0bsaxE4XMW5vD1BXb+WDZNt5dtIVmDWsz9OyWDO/eip5tYm1EW5ixZGNC0qMfraFQld8P7eJ3KMYHdWpFfnfT6JH8Aj5bvZtpK7fz3uItvPnlJlrF1OFyt/3cpMZ2qi0MWLIxIWfp5r385+vtjB3Qwe5AN9SLjmJ491YM796Kg8dOMCtjFzO+2fFd4mlcrxaXdmnOoK4t6JcSR51akX6HbEpgAwRKYAME/FNUpPzgxQXsOnCM2fdcbMNhTakOHy9g3tocZq7ayezVuzl4vIB60ZFc3CmeQV1bMKBzMxrVsRGMVckGCJiw8a9l2azMzuPp67pbojFlql87iqFnt2To2S3JLyhi4YZcZq7a6Xo+O6kVKfRtH8flqc0Z2KWZ3UDqM097NiIyGPgrEAm8pqqPFNteG3gb6AXkAtep6ia37V7gZqAQuENVZ5bVpoi8C6QBJ4DFwM9V9YSIXAx8CGx0h/1AVceXFbf1bPxx6HgBA56YS2LjuvzrtvNtKmJzWoqKlOVb9zFz1S5mrtrJ5twjAKS2bMQlnZtxSZdmdE+MtZFtHvDlCQIiEgmsBS4DsoElwGhVzQiqczvQTVVvE5FRwFWqep2IpALvA72BVsCnwMmZskpsU0SGAh+5Ou8Bn6vqSy7Z/FpVh1U0dks2/nj04zW8NHc9/xlzAee0jvU7HFMNqCrrdh9i9prdzF69m6Vb9lFYpDSpH83FneK5pHMz+qfEE1PXTrdVBr9Oo/UGslR1gwtiAjACyAiqMwJ4wC1PBp6XwHjGEcAEVT0ObBSRLNcepbWpqjNONioii4FEr96YqXybcw/z+vyNXN0zwRKNqTQiQsfmDenYvCG3XdSe/Ufymbc2hzlrdjN7zW4+WLaNqAghLakxAzs35+JO8XRo1sCGVXvAy2STAGwNWs8GziutjqoWiEge0NSVf1Vs3wS3XGabIlIL+AlwZ1BxXxFZAWwn0MtZVTxYEbkVuBWgTZs2FXh7pjI9PH01UZHC7wZ39jsUU43F1otmxDkJjDgngcIiZfmWfYFez5rdPDxjNQ/PWE3LmDr0T4mjf0o8/TrE0bh+tN9hVwvV8QrsiwROoc1368uAtqp6yJ1q+w+QUnwnVX0VeBUCp9GqKlgDC7L28EnGLn4zqBPNbWphU0UiI4S0pCakJTXht4M7s23/UeavzWH+uj3MXLWLSenZiEC3hBj6p8RzYcd4erSJpZbd03NavEw224DWQeuJrqykOtkiEgXEEBgoUNa+pbYpIvcD8cDPT5ap6oGg5Rki8qKIxKnqntN8X6YSFRQWMX5qBq2b1OXmfsl+h2NqsITYuozq3YZRvdtQWKSszN7P52v3MH9dDi/NW8/zc7JoUDuKPu2aclHHQM+nbdN6dsqtgrxMNkuAFBFJJpAQRgE/LFZnCnADsBAYCcxWVRWRKcB7IvIUgQECKQRGmElpbYrILcAgYKCqFp08gIi0AHa5dnsDEQQSmgkB7y/eQuaug7z84552M54JGZERQo82jenRpjF3XprCgWMn+DIrl/nrcvh8XQ6frt4FBBJUn3ZNOb99U/q2b0qrWBteXRrPko27BjMWmElgmPIbqrpKRMYD6ao6BXgdeMcNANhLIHng6k0iMJigABijqoUAJbXpDvkysBlY6L5pnBziPBL4hYgUAEeBUWp3soaE/UfyeXLWWvq2a8qgri38DseYUjWqU+u7WUhVlc25R5i/LoeFG3KZvWYX/1qWDUBS03r0bR/H+e2b0qddU+Ib1vY58tBhTxAogQ19rhoPTFnF2ws3Mf2O/nRp2cjvcIw5LUVFypqdB1m4IZeF6/ewaMNeDh4vAKBj8wac3z6OPu2a0qddE2LrVe/BBmc09FlEOgIvAc1V9SwR6QZcqaoPVXKcpgZZu+sg73y1mR+e18YSjQlrERFCaqtGpLZqxM39kikoLGLV9gN8uT6XhRtymbhkK29+uQkR6NS8YWBKheQm9E5qQouYmjMgptyejYjMA34DvKKqPVzZt6p6VhXE5wvr2XhLVbn+jcWs2Lqfub8ZQBMbWmqqsfyCIlZm72fh+lwWb9rLss37OJxfCEDrJnU5NymQeM5NbkK7uPphPeDgTG/qrKeqi4v9BxRUSmSmRvps9W7mr9vD/cNTLdGYai86KuK7IdYQGIG5esdBFm/ay5KNe5mXmcMHywKDauMaRJPW9r89ny4tG1ab6RMqkmz2iEh7QAFEZCSww9OoTLV1vKCQh6Zn0KFZA37cp63f4RhT5aIiIzg7MYazE2O4uV8yqsr6nMMsccln8aa9fLxqJwANakfRvXUMPds0pmebxvRoExu2130qkmzGELjZsbOIbCPwQMsfeRqVqbbeXLCJTblHeOunve3mOGMIPFKnQ7MGdGjWgNG9A08v2ZF3lMUb97J4416Wb9nPC3OyKHJXPNrF1/9e8unYvGFYPFS0IslGVfVSEakPRKjqQXefizGnZPfBYzw3O4uBnZtxUcd4v8MxJmS1jKn73WN1IDB3z4rs/Szfsv+7R+xMXhoYbh0uvZ+KJJt/AT1V9XBQ2WQC0wIYU2FPzMzkeEEhf7jCpno25lTUrx3F+e3jOL99HMB39/os27KP5Vv2s2zLPl6cu55C1/1JjqtPt8QYuiXG0j0xhq6tYqgb7e9N06UmGxHpDHQFYkTk6qBNjYCaM17PVIpvsvP459Jsfta/He3iG/gdjjFhTURIiqtPUlx9ru4ZeMD9kfwCVmzNY9mWfazYup9FG/by4dfbgcATEVKaNaB7YixnJ8bQPTGWTi0aEh1Vdaeyy+rZdAKGAbHA8KDyg8DPvAzKVC+qyoNTV9GkXjRjL+ngdzjGVEv1oqPo6x6bc9LuA8dYkZ3Hyuz9rMzO45OMnUxMDzw4Pzoqgi4tG9E9qAfULr6BZ9d/Sk02qvoh8KGI9FXVhZ4c3dQIU1fuIH3zPh65+mybE96YKtSsUR0uS63DZanNgcAXv+x9R1nhks+Krfv519Js3l64GYD60ZHcPqADYwZU/pfCilyzWS4iYwicUvvu9Jmq/rTSozHVztH8Qv4yYzVdWzXi2rTW5e9gjPGMiNC6ST1aN6nHsG6tACgsUjbkHGKl6wG1j6/vybErkmzeAdYQeKLyeALDnld7Eo2pdl6et54decf466geYTE805iaJjJCSGnekJTmDbmml3cTHFfk6lAHVf0TcFhV3wKu4H9n3DTmf2zbf5RXPl/PsG4t6Z3cxO9wjDE+qkiyOeH+3S8iZxGY4KyZdyGZ6uKRj9agCvcOtaHOxtR0FTmN9qqINAb+SGCyswbAnzyNyoS9xRv3MnXFdu4YmEKCTShlTI1XbrJR1dfc4udAOwARaeNlUCa8FRYFhjq3jKnDbRe18zscY0wIKPM0moj0FZGRItLMrXcTkfeABVUSnQlLk5duZdX2A4wb0pl60V7OPG6MCRelJhsReRx4A7gGmC4iDwGfAIuAlKoJz4Sbg8dO8PjMTNLaNubK7q38DscYEyLK6tlcAfRQ1dHA5cBdQB9V/auqHqtI4yIyWEQyRSRLRMaVsL22iEx02xeJSFLQtntdeaaIDCqvTRF515V/KyJviEgtVy4i8qyrv1JEelYkdnN6np+dRe7hfO4f3jWsJ4EyxlSuspLNsZNJRVX3AetUdVNFGxaRSOAFYAiQCowWkdRi1W4G9qlqB+Bp4FG3byowisCNpIOBF0Ukspw23wU6A2cDdYFbXPkQAj2xFOBWAlNcGw9s3HOYNxZsZGTPRM5OjPE7HGNMCCnrhHo7EZkStJ4cvK6qV5bTdm8gS1U3AIjIBGAEkBFUZwTwgFueDDwvga/DI4AJqnoc2CgiWa49SmtTVWecbFREFgMn704aAbytgfmvvxKRWBFpqao2AVwle3h6BtGREfxmcCe/QzHGhJiyks2IYutPnmLbCcDWoPVs/vdm0O/qqGqBiOQBTV35V8X2TXDLZbbpTp/9BLizjDgSKDbbqIjcSqDnQ5s2NtjuVM1bm8Onq3czbkhnmjW0h4IbY76vrAdxzqvKQCrRi8Dnqjr/VHZS1VcJzEhKWlqaehFYdXWisIg/T8ugbdN63HRBkt/hGGNCkJfjUrcBwU9eTHRlJdXJFpEoAk8nyC1n31LbFJH7gXjg56cYhzkD7361mazdh/jb9WnUjvJ3giZjTGjycuacJUCKiCSLSDSBC/5TitWZAtzglkcCs921lSnAKDdaLZnAxf3FZbUpIrcQeFjoaFUtKnaM692otD5Anl2vqTx7D+fz1Ky19E+J49Iu9hQjY0zJPOvZuGswY4GZQCTwhqquEpHxQLqqTgFeB95xAwD2EkgeuHqTCAwmKADGqGohQEltukO+DGwGFrohtx+o6nhgBjAUyAKOADd59Z5roqdnreVwfiF/GpZqQ52NMaWSQEeijAoiU4HilfKAdOCVit5zE07S0tI0PT3d7zBC3pqdBxj61/n8pE9bHhxxlt/hGGN8JiJLVTWtpG0VOY22ATgE/M29DhCYGrqjWzc1kKoyfmoGjerW4leXdfQ7HGNMiKvIabTzVfXcoPWpIrJEVc8VkVWl7mWqtU8ydvHl+lzGj+hKbL1ov8MxxoS4ivRsGgQ/5dktN3Cr+Z5EZULasROFPDx9NR2bN+CHve2eJGNM+SrSs7kH+EJE1gMCJAO3i0h94C0vgzOh6Y0FG9my9wj/uPk8oiK9HNBojKkuKjKfzQwRSSHw3DGAzKBBAc94FpkJSbsOHOP52VlcltqcfilxfodjjAkTFR363AtIcvW7iwiq+rZnUZmQ9djHmRQUKn+wqZ6NMaeg3GQjIu8A7YGvgUJXrIAlmxpmxdb9/GtZNrdd1J6kuPp+h2OMCSMV6dmkAala3g05plpTVR6Yuor4hrUZe0kHv8MxxoSZilzd/RZo4XUgJrR9+PV2lm/Zz28HdaJBbZvq2RhzairyVyMOyHBzxBw/WViB+WxMNXH4eAF/+Wg13RJjuKZnYvk7GGNMMRVJNg94HYQJbS/PW8+uA8d58Uc9iYiw558ZY05dRYY+h+u8NqYSbN17hFc+38CIc1rRq20Tv8MxxoSpUpONiHyhqv1E5CDffxCnAKqqjTyPzvjukY/WECnCuCGdy69sjDGlKGumzn7u34ZVF44JJV9tyGX6Nzu4+7KOtIyp63c4xpgwVqFhRSISCTQPrq+qW7wKyvivsEh5cGoGCbF1ufXCdn6HY4wJcxW5qfOXwP3ALuDkDJgKdPMwLuOziUu2snrHAZ7/YQ/q1LKpno0xZ6YiPZs7gU6qmut1MCY05B09wROfZNI7qQlXnN3S73CMMdVARW7q3EpgZk5TQzz32Tr2HcnnvuE21bMxpnJUpGezAZgrItP5/k2dT3kWlfHN+pxDvPnlJkad25qzEmL8DscYU01UpGezBZgFRAMNg17lEpHBIpIpIlkiMq6E7bVFZKLbvkhEkoK23evKM0VkUHltishYV6YiEhdUfrGI5InI1+51X0Vir6kempZB3VqR3HN5J79DMcZUI2X2bNwotI6q+qNTbdjt+wJwGZANLBGRKaqaEVTtZmCfqnYQkVHAo8B1IpIKjAK6Aq2AT0Xk5ET3pbW5AJgGzC0hnPmqOuxU30NNM2fNbuZk5vCHoV2Ia1Db73CMMdVImT0bVS0E2orI6Uwy3xvIUtUNqpoPTIVkH70AABaaSURBVABGFKszgv/O9jkZGCiBiwQjgAmqelxVNwJZrr1S21TV5aq66TTiNMCJwiL+PD2D5Lj63HB+kt/hGGOqmYpes1kgIlOAwycLK3DNJoHA4IKTsoHzSqujqgUikgc0deVfFds3wS2X12ZJ+orICmA78GtVXVW8gojcCtwK0KZNmwo0Wb28vXAzG3IO88aNaURH2VTPxpjKVZFks969IqjgtZoQswxoq6qHRGQo8B8gpXglVX0VeBUgLS2tRs3dk3voOM98upaLOsYzoFMzv8MxxlRDFXkQ54On2fY2oHXQeqIrK6lOtohEATFAbjn7ltfm96jqgaDlGSLyoojEqeqeU3gv1dqTs9ZyNL+QPw3rYkOdjTGeKPd8iYjEi8jjIjJDRGaffFWg7SVAiogku2s+o4ApxepMAW5wyyOB2W5G0CnAKDdaLZlAT2RxBdssHn8Ldx0IEent3rPdoOqs2p7H+4u38JO+benQLBw7rsaYcFCRk/PvAmuAZOBBYBOBP/plUtUCYCwwE1gNTFLVVSIyXkROTrz2OtBURLKAu4Fxbt9VwCQgA/gYGKOqhaW1CSAid4hINoHezkoRec0dYyTwrbtm8ywwyqa4DlBVxk/NILZuLe4a2LH8HYwx5jRJeX93RWSpqvYSkZWq2s2VLVHVc6skQh+kpaVpenq632F4bsY3O7j93WU89IOz+HGftn6HY4wJcy5fpJW0rSIDBE64f3eIyBUERnTZLFph7tiJQv5vxmo6t2jI6N41b/SdMaZqVSTZPCQiMcA9wHNAI+BXnkZlPPfa/A1k7zvKez87j0ib6tkY47GKjEab5hbzgAHehmOqws68Y7wwZz1DzmrB+e3jyt/BGGPOUEVGo3UUkc9E5Fu33k1E/uh9aMYrj368hkJVfj+0i9+hGGNqiIqMRvsbcC/u2o2qriQw5NiEoWVb9vHv5dv4Wf9kWjep53c4xpgaoiLJpp6qLi5WVuBFMMZbRW6q52YNa3P7xR38DscYU4NUJNnsEZH2BKaCRkRGAjs8jcp44t/Lt7Fi637GDelM/doVGRtijDGVoyJ/ccYQeGZYZxHZBmwETnnKAeOvQ8cLePTjNZzTOpYfnJNQ/g7GGFOJyu3ZuMf5XwrEA51VtR9wleeRmUr14pwsdh88zv3DU4mwoc7GmCpW4WfJq+phVT3oVu/2KB7jgS25R3ht/kau7pFAjzaN/Q7HGFMDne7EJfbVOIw8PCODqEjht4M7+x2KMaaGOt1kYw+yDBNfZu1h5qpdjBnQgRYxdfwOxxhTQ5U6QEBEDlJyUhGgrmcRmUpTUFjE+GkZJDauy839kv0OxxhTg5WabFTVJjcJc+8v2cqanQd5+cc9qVMr0u9wjDE1mE02X03tP5LPU59k0qddEwZ1beF3OMaYGs6STTX1zKfryDt6gvuGdbWpno0xvrNkUw2t23WQd77azOjebUht1cjvcIwxxpJNdaOqjJ+WQf3oSO6+zKZ6NsaEBk+TjYgMFpFMEckSkXElbK8tIhPd9kUikhS07V5Xnikig8prU0TGujIVkbigchGRZ922lSLS07t37L/Za3Yzf90e7rq0I00b1PY7HGOMATxMNiISCbwADAFSgdEiklqs2s3APlXtADwNPOr2TSUwjUFXYDDwoohEltPmAuBSYHOxYwwBUtzrVuClynyfoSS/oIg/T8ugfXx9ftK3rd/hGGPMd7zs2fQGstyz1fKBCcCIYnVGAG+55cnAQAlczR4BTFDV46q6Echy7ZXapqouV9VNJcQxAnhbA74CYkWkZaW+0xDx5pcb2ZR7hD8NS6VWpJ0hNcaEDi//IiUAW4PWs11ZiXVUtYDA1NNNy9i3Im2eThyIyK0iki4i6Tk5OeU0GXpyDh7nuc+yuKRzMy7u1MzvcIwx5nvs66+jqq+qapqqpsXHx/sdzil78pNMjp4o5I9X2FTPxpjQ42Wy2Qa0DlpPdGUl1hGRKCAGyC1j34q0eTpxhLVvt+UxMX0rN12QRLv4Bn6HY4wx/8PLZLMESBGRZBGJJnDBf0qxOlOAG9zySGC2qqorH+VGqyUTuLi/uIJtFjcFuN6NSusD5KlqtZlpVFV5cOoqmtSL5pcDU/wOxxhjSuRZsnHXYMYCM4HVwCRVXSUi40XkSlftdaCpiGQRmCNnnNt3FTAJyAA+BsaoamFpbQKIyB0ikk2g57JSRF5zx5gBbCAwyOBvwO1evWc/TFu5gyWb9vHrQZ1oVKeW3+EYY0yJJNCRMMHS0tI0PT3d7zDKdTS/kIFPziW2XjRTf9mPSJuB0xjjIxFZqqppJW2zAQJh7NXPN7A97xj3D0+1RGOMCWmWbMLU9v1HeWleFld0a8l57Zr6HY4xxpTJkk2YeuSjNajCvUNsqmdjTOizZBOGlmzay5QV2/n5Re1JbFzP73CMMaZclmzCTFGRMn5qBi0a1eG2i9r5HY4xxlSIJZswM3lZNt9sy+PeoZ2pF13qrN7GGBNSLNmEkYPHTvDYx5n0atuYK7u38jscY4ypMEs2YeT5OVnsOXSc+4en2lTPxpiwYskmTGzcc5g3vtjItb0S6ZYY63c4xhhzSizZhImHp68mOjKC3wzu5HcoxhhzyizZhIH563L4dPUuxl6SQrOGdfwOxxhjTpklmxBXUFjE+KkZtG1aj5/2S/I7HGOMOS2WbELcu4u2sG73If4wtAu1oyL9DscYY06LJZsQtu9wPk/NWku/DnFcltrc73CMMea0WbIJYU9/upZDxwv40zAb6myMCW+WbEJU5s6D/OOrzfzovDZ0atHQ73CMMeaMWLIJQarK+GmraFinFr+6tKPf4RhjzBmzZBOCZmXsYkFWLndf1pHG9aP9DscYY86Yp8lGRAaLSKaIZInIuBK21xaRiW77IhFJCtp2ryvPFJFB5bUpIsmujSzXZrQrv1FEckTka/e6xcv3fKaOFxTy0PTVdGzegB+d18bvcIwxplJ4lmxEJBJ4ARgCpAKjRSS1WLWbgX2q2gF4GnjU7ZsKjAK6AoOBF0Ukspw2HwWedm3tc22fNFFVz3Gv1zx4u5XmjS82sWXvEe4b1pWoSOt4GmOqBy//mvUGslR1g6rmAxOAEcXqjADecsuTgYESGHY1ApigqsdVdSOQ5dorsU23zyWuDVybP/DwvXli94FjPD97HZd2aU6/lDi/wzHGmErjZbJJALYGrWe7shLrqGoBkAc0LWPf0sqbAvtdGyUd6xoRWSkik0Wk9Zm8KS89PjOT/MIi/nhFF79DMcaYSlUTztNMBZJUtRswi//2pL5HRG4VkXQRSc/JyanSAAFWbN3PP5dm89N+ySTF1a/y4xtjjJe8TDbbgOBeRKIrK7GOiEQBMUBuGfuWVp4LxLo2vncsVc1V1eOu/DWgV0nBquqrqpqmqmnx8fGn8DbPnKry4NRVxDWozdgBHar02MYYUxW8TDZLgBQ3SiyawAX/KcXqTAFucMsjgdmqqq58lButlgykAItLa9PtM8e1gWvzQwARaRl0vCuB1ZX8Ps/YlBXbWbZlP78d3ImGdWr5HY4xxlQ6zyaxV9UCERkLzAQigTdUdZWIjAfSVXUK8DrwjohkAXsJJA9cvUlABlAAjFHVQoCS2nSH/B0wQUQeApa7tgHuEJErXTt7gRu9es+n40h+AX+ZsYazE2IY2TPR73CMMcYTEugUmGBpaWmanp5eJcd6atZanv1sHZNv60taUpMqOaYxxnhBRJaqalpJ22rCAIGQlb3vCK/MW8+V3VtZojHGVGuWbHz0l4/WIALjhnT2OxRjjPGUJRufLNqQy/SVO/jFRR1oFVvX73CMMcZTlmx8UFikPDg1g4TYutx6YTu/wzHGGM9ZsvHBpPStZOw4wLghnakbbVM9G2OqP0s2VezAsRM8MTOTc5MaM6xby/J3MMaYasCz+2xMyZ77bB17j+Tz1vDeNtWzMabGsJ5NFVqfc4i/L9jEdWmtOSshxu9wjDGmyliyqUIPT19N3VqR3HN5J79DMcaYKmXJporMzdzN7DW7uWNgCvENa/sdjjHGVClLNlXgRGERf56WQXJcfW44P8nvcIwxpspZsqkC7yzczPqcw/zxii5ER9l/uTGm5rG/fB7LPXScpz9dy4Ud47mkczO/wzHGGF9YsvHYU7PWciS/kPuGdbGhzsaYGsuSjYcyth/g/cVbuL5vWzo0a+h3OMYY4xtLNh5RVcZPW0VM3VrcNbCj3+EYY4yvLNl4ZOaqnXy1YS93X96JmHo21bMxpmazZOOBYycKeWj6ajq3aMjoc1v7HY4xxvjOko0HXv9iI9n7jnLfsFSiIu2/2BhjPP1LKCKDRSRTRLJEZFwJ22uLyES3fZGIJAVtu9eVZ4rIoPLaFJFk10aWazO6vGN4YWfeMV6Yk8Xgri04v0Ocl4cyxpiw4VmyEZFI4AVgCJAKjBaR1GLVbgb2qWoH4GngUbdvKjAK6AoMBl4Ukchy2nwUeNq1tc+1XeoxvPLYx2soKFJ+P7SLl4cxxpiw4mXPpjeQpaobVDUfmACMKFZnBPCWW54MDJTAzSgjgAmqelxVNwJZrr0S23T7XOLawLX5g3KOUemWb9nHB8u3cUu/ZNo0refFIYwxJix5mWwSgK1B69murMQ6qloA5AFNy9i3tPKmwH7XRvFjlXaM7xGRW0UkXUTSc3JyTumNBrVB/5Q4bh/Q4bT2N8aY6squXjuq+qqqpqlqWnx8/Gm1cU7rWN65+Twa1LY56YwxJpiXyWYbEDzuN9GVlVhHRKKAGCC3jH1LK88FYl0bxY9V2jGMMcZUES+TzRIgxY0SiyZwwX9KsTpTgBvc8khgtqqqKx/lRpIlAynA4tLadPvMcW3g2vywnGMYY4ypIp6d71HVAhEZC8wEIoE3VHWViIwH0lV1CvA68I6IZAF7CSQPXL1JQAZQAIxR1UKAktp0h/wdMEFEHgKWu7Yp7RjGGGOqjtiX/P+Vlpam6enpfodhjDFhRUSWqmpaSdtsgIAxxhjPWbIxxhjjOUs2xhhjPGfJxhhjjOdsgEAJRCQH2Hyau8cBeyoxnMoSqnFB6MZmcZ0ai+vUVMe42qpqiXfFW7KpZCKSXtpoDD+FalwQurFZXKfG4jo1NS0uO41mjDHGc5ZsjDHGeM6STeV71e8AShGqcUHoxmZxnRqL69TUqLjsmo0xxhjPWc/GGGOM5yzZGGOM8Zwlm0okIoNFJFNEskRknEfHeENEdovIt0FlTURkloisc/82duUiIs+6eFaKSM+gfW5w9deJyA1B5b1E5Bu3z7MVnUJbRFqLyBwRyRCRVSJyZyjEJiJ1RGSxiKxwcT3oypNFZJFra6KbsgI3rcVEV75IRJKC2rrXlWeKyKCg8tP6uYtIpIgsF5FpoRKT23eT+3/+WkTSXVkofMZiRWSyiKwRkdUi0tfvuESkk/t/Ovk6ICJ3+R2X2+9X7jP/rYi8L4HfBf8+Y6pqr0p4EZjyYD3QDogGVgCpHhznQqAn8G1Q2WPAOLc8DnjULQ8FPgIE6AMscuVNgA3u38ZuubHbttjVFbfvkArG1RLo6ZYbAmuBVL9jc3UbuOVawCLXxiRglCt/GfiFW74deNktjwImuuVU9zOtDSS7n3XkmfzcgbuB94Bpbt33mFy7m4C4YmWh8Bl7C7jFLUcDsaEQV7G/ATuBtn7HBSQAG4G6QZ+tG/38jPn+R7q6vIC+wMyg9XuBez06VhLfTzaZQEu33BLIdMuvAKOL1wNGA68Elb/iyloCa4LKv1fvFGP8ELgslGID6gHLgPMI3CEdVfxnR2CupL5uOcrVk+I/z5P1TvfnTmA22c+AS4Bp7hi+xhRUfxP/m2x8/TkSmGF3I25QU6jEVSyWy4EFoRAXgWSzlUDyinKfsUF+fsbsNFrlOfnDPSnblVWF5qq6wy3vBJqXE1NZ5dkllJ8S1wXvQaAX4XtsEjhd9TWwG5hF4BvZflUtKKGt747vtucBTU8j3vI8A/wWKHLrTUMgppMU+ERElorIra7M759jMpAD/F0Cpx5fE5H6IRBXsFHA+27Z17hUdRvwBLAF2EHgM7MUHz9jlmyqGQ18zfBtPLuINAD+BdylqgeCt/kVm6oWquo5BHoTvYHOVR1DMBEZBuxW1aV+xlGGfqraExgCjBGRC4M3+vRzjCJw+vglVe0BHCZwesrvuABw1z6uBP5ZfJsfcblrRCMIJOlWQH1gcFXGUJwlm8qzDWgdtJ7oyqrCLhFpCeD+3V1OTGWVJ5ZQXiEiUotAonlXVT8IpdgAVHU/MIfAKYBYETk5LXpwW98d322PAXJPI96yXABcKSKbgAkETqX91eeYvuO+FaOqu4F/E0jQfv8cs4FsVV3k1icTSD5+x3XSEGCZqu5y637HdSmwUVVzVPUE8AGBz51/n7FTOSdprzLPkUYRuKiXzH8vmHX16FhJfP+azeN8/2LkY275Cr5/MXKxK29C4Px3Y/faCDRx24pfjBxawZgEeBt4pli5r7EB8UCsW64LzAeGEfgGGnyh9Ha3PIbvXyid5Ja78v0LpRsIXCQ9o587cDH/HSDge0wEvgE3DFr+ksA34lD4jM0HOrnlB1xMvsfl9p0A3BRCn/vzgFUErlMKgcEVv/TzM+b7H+nq9CIw0mQtgWsCf/DoGO8TOAd7gsC3vZsJnFv9DFgHfBr0IRXgBRfPN0BaUDs/BbLcK/iXJA341u3zPMUuyJYRVz8CpwpWAl+711C/YwO6ActdXN8C97nydu6XOMv9AtZ25XXcepbb3i6orT+4Y2cSNCLoTH7ufD/Z+B6Ti2GFe606ua/fP0e33zlAuvtZ/ofAH+VQiKs+gV5ATFBZKMT1ILDG7fsOgYTh22fMHldjjDHGc3bNxhhjjOcs2RhjjPGcJRtjjDGes2RjjDHGc5ZsjDHGeM6SjTGVSESaBj0BeKeIbAtajy5n3zQRefYUj/dT90Tgle7pviNc+Y0i0upM3osxlcmGPhvjERF5ADikqk8ElUXpf59NdabtJwLzCDxtO889KiheVTeKyFzg16qaXhnHMuZMWc/GGI+JyJsi8rKILAIeE5HeIrLQPVDySxHp5OpdLP+d2+YBCcxdNFdENojIHSU03Qw4CBwCUNVDLtGMJHAj4LuuR1XXzYkyzz1cc2bQo1TmishfXb1vRaR3VfyfmJrHko0xVSMROF9V7yZwV3d/DTxQ8j7g/0rZpzOBx8L3Bu53z54LtgLYBWwUkb+LyHAAVZ1M4E77H2ngAaQFwHPASFXtBbwBPBzUTj1X73a3zZhKF1V+FWNMJfinqha65RjgLRFJIfCIn+JJ5KTpqnocOC4iuwk8pv67x82raqGIDAbOBQYCT4tIL1V9oFg7nYCzgFluksdIAo88Oul9197nItJIRGI18NBSYyqNJRtjqsbhoOU/A3NU9So398/cUvY5HrRcSAm/rxq46LoYWCwis4C/E3hIZTABVqlq31KOU/zCrV3INZXOTqMZU/Vi+O/j2G883UZEpJUEzWFP4EGVm93yQQLTc0PgAYrxItLX7VdLRLoG7XedK+8H5Klq3unGZExprGdjTNV7jMBptD8C08+gnVrAE26I8zECM1ne5ra9CbwsIkcJzN8zEnhWRGII/N4/Q+CpzgDHRGS5a++nZxCPMaWyoc/G1GA2RNpUFTuNZowxxnPWszHGGOM569kYY4zxnCUbY4wxnrNkY4wxxnOWbIwxxnjOko0xxhjP/X87PxAjOvWlagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(80000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Sv_PpN0NEBuf"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, label_smoothing=0.1, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ClXDQkJ9EDqe"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  real_ = tf.one_hot(tf.cast(real, tf.int64), tokenizers.vi.get_vocab_size())\n",
    "\n",
    "  loss_ = loss_object(real_, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9VopW9uaEEWf"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "\n",
    "validation_loss = tf.keras.metrics.Mean(name='validation_loss')\n",
    "validation_accuracy = tf.keras.metrics.Mean(name='validation_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "9iOcJJBmEHgJ"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=tokenizers.en.get_vocab_size(),\n",
    "    target_vocab_size=tokenizers.vi.get_vocab_size(),\n",
    "    pe_input=1000,\n",
    "    pe_target=1000,\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "YMq3YJ1FEJgz"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Tạo padding mask cho encoder\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "  # Dùng trong tầng attention thứ hai trong decoder\n",
    "  # Mask này để che đi output của encoder\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "  # Tạo mask cho tầng attention thứ nhất của decoder\n",
    "  # Dùng để padding và che các từ chưa được dịch từ đầu vào của decoder\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "egyYBrmFELrQ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "tmA2v2V-ENlK"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Pb_bPEnWEQTt"
   },
   "outputs": [],
   "source": [
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1] # đầu vào cho decoder\n",
    "  tar_real = tar[:, 1:] # đầu ra cho mô hình\n",
    "\n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp,\n",
    "                                 True,\n",
    "                                 enc_padding_mask,\n",
    "                                 combined_mask,\n",
    "                                 dec_padding_mask)\n",
    "    # tính lỗi\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "  \n",
    "    \n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(accuracy_function(tar_real, predictions))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqEKQF7lETEW",
    "outputId": "31f289e9-dc7a-4cdf-a30b-da33e96a3489"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.4041 Accuracy 0.0000\n",
      "Epoch 1 Batch 200 Loss 8.2995 Accuracy 0.0156\n",
      "Epoch 1 Batch 400 Loss 8.1519 Accuracy 0.0264\n",
      "Epoch 1 Batch 600 Loss 8.0186 Accuracy 0.0309\n",
      "Epoch 1 Batch 800 Loss 7.8771 Accuracy 0.0346\n",
      "Epoch 1 Batch 1000 Loss 7.7215 Accuracy 0.0406\n",
      "Epoch 1 Batch 1200 Loss 7.5652 Accuracy 0.0474\n",
      "Epoch 1 Batch 1400 Loss 7.4244 Accuracy 0.0539\n",
      "Epoch 1 Batch 1600 Loss 7.3062 Accuracy 0.0596\n",
      "Epoch 1 Batch 1800 Loss 7.2075 Accuracy 0.0653\n",
      "Epoch 1 Batch 2000 Loss 7.1226 Accuracy 0.0709\n",
      "Epoch 1 Batch 2200 Loss 7.0454 Accuracy 0.0764\n",
      "Saving checkpoint for epoch 1 at ./checkpoints/train/ckpt-1\n",
      "Epoch 1 Loss 7.0060 Accuracy 0.0794\n",
      "Validation loss: 6.2116 Validation accuracy 0.1388\n",
      "Time taken for 1 epoch: 269.47 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 6.3748 Accuracy 0.1323\n",
      "Epoch 2 Batch 200 Loss 6.1839 Accuracy 0.1422\n",
      "Epoch 2 Batch 400 Loss 6.1485 Accuracy 0.1459\n",
      "Epoch 2 Batch 600 Loss 6.1035 Accuracy 0.1501\n",
      "Epoch 2 Batch 800 Loss 6.0661 Accuracy 0.1538\n",
      "Epoch 2 Batch 1000 Loss 6.0321 Accuracy 0.1572\n",
      "Epoch 2 Batch 1200 Loss 5.9982 Accuracy 0.1606\n",
      "Epoch 2 Batch 1400 Loss 5.9648 Accuracy 0.1641\n",
      "Epoch 2 Batch 1600 Loss 5.9333 Accuracy 0.1673\n",
      "Epoch 2 Batch 1800 Loss 5.9015 Accuracy 0.1709\n",
      "Epoch 2 Batch 2000 Loss 5.8672 Accuracy 0.1748\n",
      "Epoch 2 Batch 2200 Loss 5.8345 Accuracy 0.1786\n",
      "Saving checkpoint for epoch 2 at ./checkpoints/train/ckpt-2\n",
      "Epoch 2 Loss 5.8172 Accuracy 0.1806\n",
      "Validation loss: 5.4643 Validation accuracy 0.2182\n",
      "Time taken for 1 epoch: 255.81 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 5.5147 Accuracy 0.2329\n",
      "Epoch 3 Batch 200 Loss 5.4429 Accuracy 0.2228\n",
      "Epoch 3 Batch 400 Loss 5.4040 Accuracy 0.2281\n",
      "Epoch 3 Batch 600 Loss 5.3756 Accuracy 0.2316\n",
      "Epoch 3 Batch 800 Loss 5.3502 Accuracy 0.2343\n",
      "Epoch 3 Batch 1000 Loss 5.3288 Accuracy 0.2366\n",
      "Epoch 3 Batch 1200 Loss 5.3108 Accuracy 0.2386\n",
      "Epoch 3 Batch 1400 Loss 5.2912 Accuracy 0.2405\n",
      "Epoch 3 Batch 1600 Loss 5.2719 Accuracy 0.2425\n",
      "Epoch 3 Batch 1800 Loss 5.2508 Accuracy 0.2450\n",
      "Epoch 3 Batch 2000 Loss 5.2293 Accuracy 0.2475\n",
      "Epoch 3 Batch 2200 Loss 5.2080 Accuracy 0.2499\n",
      "Saving checkpoint for epoch 3 at ./checkpoints/train/ckpt-3\n",
      "Epoch 3 Loss 5.1957 Accuracy 0.2514\n",
      "Validation loss: 4.9968 Validation accuracy 0.2706\n",
      "Time taken for 1 epoch: 248.48 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 4.8279 Accuracy 0.2898\n",
      "Epoch 4 Batch 200 Loss 4.9563 Accuracy 0.2786\n",
      "Epoch 4 Batch 400 Loss 4.9294 Accuracy 0.2819\n",
      "Epoch 4 Batch 600 Loss 4.9069 Accuracy 0.2849\n",
      "Epoch 4 Batch 800 Loss 4.8858 Accuracy 0.2881\n",
      "Epoch 4 Batch 1000 Loss 4.8682 Accuracy 0.2907\n",
      "Epoch 4 Batch 1200 Loss 4.8493 Accuracy 0.2933\n",
      "Epoch 4 Batch 1400 Loss 4.8332 Accuracy 0.2955\n",
      "Epoch 4 Batch 1600 Loss 4.8151 Accuracy 0.2978\n",
      "Epoch 4 Batch 1800 Loss 4.7967 Accuracy 0.3003\n",
      "Epoch 4 Batch 2000 Loss 4.7801 Accuracy 0.3025\n",
      "Epoch 4 Batch 2200 Loss 4.7633 Accuracy 0.3048\n",
      "Saving checkpoint for epoch 4 at ./checkpoints/train/ckpt-4\n",
      "Epoch 4 Loss 4.7550 Accuracy 0.3060\n",
      "Validation loss: 4.6435 Validation accuracy 0.3218\n",
      "Time taken for 1 epoch: 250.22 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 4.5480 Accuracy 0.3303\n",
      "Epoch 5 Batch 200 Loss 4.5689 Accuracy 0.3311\n",
      "Epoch 5 Batch 400 Loss 4.5410 Accuracy 0.3347\n",
      "Epoch 5 Batch 600 Loss 4.5151 Accuracy 0.3384\n",
      "Epoch 5 Batch 800 Loss 4.5009 Accuracy 0.3405\n",
      "Epoch 5 Batch 1000 Loss 4.4872 Accuracy 0.3428\n",
      "Epoch 5 Batch 1200 Loss 4.4719 Accuracy 0.3449\n",
      "Epoch 5 Batch 1400 Loss 4.4597 Accuracy 0.3465\n",
      "Epoch 5 Batch 1600 Loss 4.4463 Accuracy 0.3486\n",
      "Epoch 5 Batch 1800 Loss 4.4331 Accuracy 0.3506\n",
      "Epoch 5 Batch 2000 Loss 4.4205 Accuracy 0.3524\n",
      "Epoch 5 Batch 2200 Loss 4.4089 Accuracy 0.3543\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-5\n",
      "Epoch 5 Loss 4.4015 Accuracy 0.3554\n",
      "Validation loss: 4.3736 Validation accuracy 0.3618\n",
      "Time taken for 1 epoch: 246.84 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 4.2825 Accuracy 0.3808\n",
      "Epoch 6 Batch 200 Loss 4.2466 Accuracy 0.3777\n",
      "Epoch 6 Batch 400 Loss 4.2214 Accuracy 0.3813\n",
      "Epoch 6 Batch 600 Loss 4.1943 Accuracy 0.3849\n",
      "Epoch 6 Batch 800 Loss 4.1852 Accuracy 0.3874\n",
      "Epoch 6 Batch 1000 Loss 4.1708 Accuracy 0.3901\n",
      "Epoch 6 Batch 1200 Loss 4.1629 Accuracy 0.3915\n",
      "Epoch 6 Batch 1400 Loss 4.1538 Accuracy 0.3929\n",
      "Epoch 6 Batch 1600 Loss 4.1456 Accuracy 0.3943\n",
      "Epoch 6 Batch 1800 Loss 4.1368 Accuracy 0.3959\n",
      "Epoch 6 Batch 2000 Loss 4.1241 Accuracy 0.3981\n",
      "Epoch 6 Batch 2200 Loss 4.1117 Accuracy 0.4001\n",
      "Saving checkpoint for epoch 6 at ./checkpoints/train/ckpt-6\n",
      "Epoch 6 Loss 4.1071 Accuracy 0.4008\n",
      "Validation loss: 4.1492 Validation accuracy 0.3984\n",
      "Time taken for 1 epoch: 250.58 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 3.8752 Accuracy 0.4211\n",
      "Epoch 7 Batch 200 Loss 3.9529 Accuracy 0.4230\n",
      "Epoch 7 Batch 400 Loss 3.9488 Accuracy 0.4242\n",
      "Epoch 7 Batch 600 Loss 3.9319 Accuracy 0.4272\n",
      "Epoch 7 Batch 800 Loss 3.9194 Accuracy 0.4294\n",
      "Epoch 7 Batch 1000 Loss 3.9108 Accuracy 0.4313\n",
      "Epoch 7 Batch 1200 Loss 3.9014 Accuracy 0.4331\n",
      "Epoch 7 Batch 1400 Loss 3.8936 Accuracy 0.4345\n",
      "Epoch 7 Batch 1600 Loss 3.8858 Accuracy 0.4360\n",
      "Epoch 7 Batch 1800 Loss 3.8776 Accuracy 0.4374\n",
      "Epoch 7 Batch 2000 Loss 3.8670 Accuracy 0.4393\n",
      "Epoch 7 Batch 2200 Loss 3.8600 Accuracy 0.4405\n",
      "Saving checkpoint for epoch 7 at ./checkpoints/train/ckpt-7\n",
      "Epoch 7 Loss 3.8554 Accuracy 0.4413\n",
      "Validation loss: 3.9800 Validation accuracy 0.4313\n",
      "Time taken for 1 epoch: 249.64 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 3.8115 Accuracy 0.4646\n",
      "Epoch 8 Batch 200 Loss 3.7336 Accuracy 0.4590\n",
      "Epoch 8 Batch 400 Loss 3.7139 Accuracy 0.4619\n",
      "Epoch 8 Batch 600 Loss 3.7022 Accuracy 0.4645\n",
      "Epoch 8 Batch 800 Loss 3.6888 Accuracy 0.4673\n",
      "Epoch 8 Batch 1000 Loss 3.6829 Accuracy 0.4687\n",
      "Epoch 8 Batch 1200 Loss 3.6773 Accuracy 0.4695\n",
      "Epoch 8 Batch 1400 Loss 3.6749 Accuracy 0.4699\n",
      "Epoch 8 Batch 1600 Loss 3.6731 Accuracy 0.4703\n",
      "Epoch 8 Batch 1800 Loss 3.6687 Accuracy 0.4712\n",
      "Epoch 8 Batch 2000 Loss 3.6613 Accuracy 0.4727\n",
      "Epoch 8 Batch 2200 Loss 3.6562 Accuracy 0.4735\n",
      "Saving checkpoint for epoch 8 at ./checkpoints/train/ckpt-8\n",
      "Epoch 8 Loss 3.6538 Accuracy 0.4740\n",
      "Validation loss: 3.8544 Validation accuracy 0.4453\n",
      "Time taken for 1 epoch: 250.97 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 3.6724 Accuracy 0.4807\n",
      "Epoch 9 Batch 200 Loss 3.5577 Accuracy 0.4904\n",
      "Epoch 9 Batch 400 Loss 3.5438 Accuracy 0.4916\n",
      "Epoch 9 Batch 600 Loss 3.5292 Accuracy 0.4936\n",
      "Epoch 9 Batch 800 Loss 3.5216 Accuracy 0.4949\n",
      "Epoch 9 Batch 1000 Loss 3.5171 Accuracy 0.4956\n",
      "Epoch 9 Batch 1200 Loss 3.5121 Accuracy 0.4967\n",
      "Epoch 9 Batch 1400 Loss 3.5088 Accuracy 0.4974\n",
      "Epoch 9 Batch 1600 Loss 3.5086 Accuracy 0.4974\n",
      "Epoch 9 Batch 1800 Loss 3.5036 Accuracy 0.4985\n",
      "Epoch 9 Batch 2000 Loss 3.4997 Accuracy 0.4992\n",
      "Epoch 9 Batch 2200 Loss 3.4958 Accuracy 0.5000\n",
      "Saving checkpoint for epoch 9 at ./checkpoints/train/ckpt-9\n",
      "Epoch 9 Loss 3.4939 Accuracy 0.5004\n",
      "Validation loss: 3.7319 Validation accuracy 0.4655\n",
      "Time taken for 1 epoch: 251.24 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 3.3892 Accuracy 0.5198\n",
      "Epoch 10 Batch 200 Loss 3.4161 Accuracy 0.5111\n",
      "Epoch 10 Batch 400 Loss 3.3969 Accuracy 0.5145\n",
      "Epoch 10 Batch 600 Loss 3.3866 Accuracy 0.5161\n",
      "Epoch 10 Batch 800 Loss 3.3884 Accuracy 0.5160\n",
      "Epoch 10 Batch 1000 Loss 3.3828 Accuracy 0.5173\n",
      "Epoch 10 Batch 1200 Loss 3.3809 Accuracy 0.5175\n",
      "Epoch 10 Batch 1400 Loss 3.3783 Accuracy 0.5181\n",
      "Epoch 10 Batch 1600 Loss 3.3782 Accuracy 0.5184\n",
      "Epoch 10 Batch 1800 Loss 3.3787 Accuracy 0.5185\n",
      "Epoch 10 Batch 2000 Loss 3.3753 Accuracy 0.5193\n",
      "Epoch 10 Batch 2200 Loss 3.3709 Accuracy 0.5202\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-10\n",
      "Epoch 10 Loss 3.3691 Accuracy 0.5205\n",
      "Validation loss: 3.6762 Validation accuracy 0.4778\n",
      "Time taken for 1 epoch: 252.04 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 3.3197 Accuracy 0.5234\n",
      "Epoch 11 Batch 200 Loss 3.2943 Accuracy 0.5298\n",
      "Epoch 11 Batch 400 Loss 3.2802 Accuracy 0.5327\n",
      "Epoch 11 Batch 600 Loss 3.2690 Accuracy 0.5350\n",
      "Epoch 11 Batch 800 Loss 3.2684 Accuracy 0.5354\n",
      "Epoch 11 Batch 1000 Loss 3.2657 Accuracy 0.5362\n",
      "Epoch 11 Batch 1200 Loss 3.2667 Accuracy 0.5364\n",
      "Epoch 11 Batch 1400 Loss 3.2674 Accuracy 0.5365\n",
      "Epoch 11 Batch 1600 Loss 3.2692 Accuracy 0.5363\n",
      "Epoch 11 Batch 1800 Loss 3.2696 Accuracy 0.5364\n",
      "Epoch 11 Batch 2000 Loss 3.2653 Accuracy 0.5373\n",
      "Epoch 11 Batch 2200 Loss 3.2640 Accuracy 0.5377\n",
      "Saving checkpoint for epoch 11 at ./checkpoints/train/ckpt-11\n",
      "Epoch 11 Loss 3.2644 Accuracy 0.5376\n",
      "Validation loss: 3.6248 Validation accuracy 0.4849\n",
      "Time taken for 1 epoch: 252.33 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 3.2899 Accuracy 0.5420\n",
      "Epoch 12 Batch 200 Loss 3.2319 Accuracy 0.5389\n",
      "Epoch 12 Batch 400 Loss 3.2066 Accuracy 0.5442\n",
      "Epoch 12 Batch 600 Loss 3.1973 Accuracy 0.5467\n",
      "Epoch 12 Batch 800 Loss 3.1904 Accuracy 0.5482\n",
      "Epoch 12 Batch 1000 Loss 3.1834 Accuracy 0.5499\n",
      "Epoch 12 Batch 1200 Loss 3.1845 Accuracy 0.5498\n",
      "Epoch 12 Batch 1400 Loss 3.1864 Accuracy 0.5497\n",
      "Epoch 12 Batch 1600 Loss 3.1860 Accuracy 0.5497\n",
      "Epoch 12 Batch 1800 Loss 3.1854 Accuracy 0.5499\n",
      "Epoch 12 Batch 2000 Loss 3.1852 Accuracy 0.5501\n",
      "Epoch 12 Batch 2200 Loss 3.1832 Accuracy 0.5506\n",
      "Saving checkpoint for epoch 12 at ./checkpoints/train/ckpt-12\n",
      "Epoch 12 Loss 3.1828 Accuracy 0.5507\n",
      "Validation loss: 3.5923 Validation accuracy 0.4889\n",
      "Time taken for 1 epoch: 251.45 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 3.3001 Accuracy 0.5358\n",
      "Epoch 13 Batch 200 Loss 3.1214 Accuracy 0.5579\n",
      "Epoch 13 Batch 400 Loss 3.1180 Accuracy 0.5587\n",
      "Epoch 13 Batch 600 Loss 3.1097 Accuracy 0.5614\n",
      "Epoch 13 Batch 800 Loss 3.1090 Accuracy 0.5616\n",
      "Epoch 13 Batch 1000 Loss 3.1099 Accuracy 0.5617\n",
      "Epoch 13 Batch 1200 Loss 3.1113 Accuracy 0.5617\n",
      "Epoch 13 Batch 1400 Loss 3.1150 Accuracy 0.5610\n",
      "Epoch 13 Batch 1600 Loss 3.1154 Accuracy 0.5611\n",
      "Epoch 13 Batch 1800 Loss 3.1147 Accuracy 0.5614\n",
      "Epoch 13 Batch 2000 Loss 3.1149 Accuracy 0.5616\n",
      "Epoch 13 Batch 2200 Loss 3.1151 Accuracy 0.5618\n",
      "Saving checkpoint for epoch 13 at ./checkpoints/train/ckpt-13\n",
      "Epoch 13 Loss 3.1156 Accuracy 0.5617\n",
      "Validation loss: 3.5487 Validation accuracy 0.4976\n",
      "Time taken for 1 epoch: 248.26 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 3.1064 Accuracy 0.5658\n",
      "Epoch 14 Batch 200 Loss 3.0622 Accuracy 0.5693\n",
      "Epoch 14 Batch 400 Loss 3.0443 Accuracy 0.5720\n",
      "Epoch 14 Batch 600 Loss 3.0418 Accuracy 0.5728\n",
      "Epoch 14 Batch 800 Loss 3.0428 Accuracy 0.5730\n",
      "Epoch 14 Batch 1000 Loss 3.0422 Accuracy 0.5733\n",
      "Epoch 14 Batch 1200 Loss 3.0425 Accuracy 0.5732\n",
      "Epoch 14 Batch 1400 Loss 3.0480 Accuracy 0.5724\n",
      "Epoch 14 Batch 1600 Loss 3.0477 Accuracy 0.5724\n",
      "Epoch 14 Batch 1800 Loss 3.0473 Accuracy 0.5728\n",
      "Epoch 14 Batch 2000 Loss 3.0457 Accuracy 0.5733\n",
      "Epoch 14 Batch 2200 Loss 3.0460 Accuracy 0.5733\n",
      "Saving checkpoint for epoch 14 at ./checkpoints/train/ckpt-14\n",
      "Epoch 14 Loss 3.0467 Accuracy 0.5733\n",
      "Validation loss: 3.5052 Validation accuracy 0.5021\n",
      "Time taken for 1 epoch: 247.36 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 3.1401 Accuracy 0.5760\n",
      "Epoch 15 Batch 200 Loss 2.9869 Accuracy 0.5815\n",
      "Epoch 15 Batch 400 Loss 2.9713 Accuracy 0.5836\n",
      "Epoch 15 Batch 600 Loss 2.9690 Accuracy 0.5847\n",
      "Epoch 15 Batch 800 Loss 2.9661 Accuracy 0.5857\n",
      "Epoch 15 Batch 1000 Loss 2.9651 Accuracy 0.5863\n",
      "Epoch 15 Batch 1200 Loss 2.9662 Accuracy 0.5861\n",
      "Epoch 15 Batch 1400 Loss 2.9702 Accuracy 0.5855\n",
      "Epoch 15 Batch 1600 Loss 2.9703 Accuracy 0.5857\n",
      "Epoch 15 Batch 1800 Loss 2.9709 Accuracy 0.5856\n",
      "Epoch 15 Batch 2000 Loss 2.9703 Accuracy 0.5859\n",
      "Epoch 15 Batch 2200 Loss 2.9721 Accuracy 0.5856\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-15\n",
      "Epoch 15 Loss 2.9721 Accuracy 0.5857\n",
      "Validation loss: 3.4875 Validation accuracy 0.5062\n",
      "Time taken for 1 epoch: 246.57 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 2.7647 Accuracy 0.6195\n",
      "Epoch 16 Batch 200 Loss 2.9201 Accuracy 0.5924\n",
      "Epoch 16 Batch 400 Loss 2.9066 Accuracy 0.5946\n",
      "Epoch 16 Batch 600 Loss 2.9028 Accuracy 0.5961\n",
      "Epoch 16 Batch 800 Loss 2.8996 Accuracy 0.5968\n",
      "Epoch 16 Batch 1000 Loss 2.9007 Accuracy 0.5970\n",
      "Epoch 16 Batch 1200 Loss 2.9048 Accuracy 0.5963\n",
      "Epoch 16 Batch 1400 Loss 2.9030 Accuracy 0.5968\n",
      "Epoch 16 Batch 1600 Loss 2.9061 Accuracy 0.5962\n",
      "Epoch 16 Batch 1800 Loss 2.9051 Accuracy 0.5966\n",
      "Epoch 16 Batch 2000 Loss 2.9057 Accuracy 0.5965\n",
      "Epoch 16 Batch 2200 Loss 2.9058 Accuracy 0.5967\n",
      "Saving checkpoint for epoch 16 at ./checkpoints/train/ckpt-16\n",
      "Epoch 16 Loss 2.9067 Accuracy 0.5965\n",
      "Validation loss: 3.4629 Validation accuracy 0.5121\n",
      "Time taken for 1 epoch: 249.25 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 2.9352 Accuracy 0.5714\n",
      "Epoch 17 Batch 200 Loss 2.8487 Accuracy 0.6048\n",
      "Epoch 17 Batch 400 Loss 2.8512 Accuracy 0.6042\n",
      "Epoch 17 Batch 600 Loss 2.8431 Accuracy 0.6065\n",
      "Epoch 17 Batch 800 Loss 2.8430 Accuracy 0.6068\n",
      "Epoch 17 Batch 1000 Loss 2.8427 Accuracy 0.6073\n",
      "Epoch 17 Batch 1200 Loss 2.8450 Accuracy 0.6069\n",
      "Epoch 17 Batch 1400 Loss 2.8463 Accuracy 0.6067\n",
      "Epoch 17 Batch 1600 Loss 2.8491 Accuracy 0.6063\n",
      "Epoch 17 Batch 1800 Loss 2.8509 Accuracy 0.6061\n",
      "Epoch 17 Batch 2000 Loss 2.8491 Accuracy 0.6064\n",
      "Epoch 17 Batch 2200 Loss 2.8491 Accuracy 0.6065\n",
      "Saving checkpoint for epoch 17 at ./checkpoints/train/ckpt-17\n",
      "Epoch 17 Loss 2.8490 Accuracy 0.6066\n",
      "Validation loss: 3.4460 Validation accuracy 0.5151\n",
      "Time taken for 1 epoch: 250.10 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 2.8803 Accuracy 0.5844\n",
      "Epoch 18 Batch 200 Loss 2.8072 Accuracy 0.6127\n",
      "Epoch 18 Batch 400 Loss 2.8046 Accuracy 0.6132\n",
      "Epoch 18 Batch 600 Loss 2.7904 Accuracy 0.6154\n",
      "Epoch 18 Batch 800 Loss 2.7922 Accuracy 0.6154\n",
      "Epoch 18 Batch 1000 Loss 2.7904 Accuracy 0.6161\n",
      "Epoch 18 Batch 1200 Loss 2.7930 Accuracy 0.6158\n",
      "Epoch 18 Batch 1400 Loss 2.7947 Accuracy 0.6157\n",
      "Epoch 18 Batch 1600 Loss 2.7975 Accuracy 0.6153\n",
      "Epoch 18 Batch 1800 Loss 2.7985 Accuracy 0.6153\n",
      "Epoch 18 Batch 2000 Loss 2.7986 Accuracy 0.6155\n",
      "Epoch 18 Batch 2200 Loss 2.7989 Accuracy 0.6155\n",
      "Saving checkpoint for epoch 18 at ./checkpoints/train/ckpt-18\n",
      "Epoch 18 Loss 2.7987 Accuracy 0.6155\n",
      "Validation loss: 3.4475 Validation accuracy 0.5144\n",
      "Time taken for 1 epoch: 251.29 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 2.7355 Accuracy 0.6229\n",
      "Epoch 19 Batch 200 Loss 2.7624 Accuracy 0.6203\n",
      "Epoch 19 Batch 400 Loss 2.7493 Accuracy 0.6227\n",
      "Epoch 19 Batch 600 Loss 2.7455 Accuracy 0.6234\n",
      "Epoch 19 Batch 800 Loss 2.7420 Accuracy 0.6245\n",
      "Epoch 19 Batch 1000 Loss 2.7413 Accuracy 0.6250\n",
      "Epoch 19 Batch 1200 Loss 2.7432 Accuracy 0.6247\n",
      "Epoch 19 Batch 1400 Loss 2.7474 Accuracy 0.6240\n",
      "Epoch 19 Batch 1600 Loss 2.7502 Accuracy 0.6235\n",
      "Epoch 19 Batch 1800 Loss 2.7493 Accuracy 0.6239\n",
      "Epoch 19 Batch 2000 Loss 2.7517 Accuracy 0.6237\n",
      "Epoch 19 Batch 2200 Loss 2.7524 Accuracy 0.6236\n",
      "Saving checkpoint for epoch 19 at ./checkpoints/train/ckpt-19\n",
      "Epoch 19 Loss 2.7527 Accuracy 0.6236\n",
      "Validation loss: 3.4340 Validation accuracy 0.5175\n",
      "Time taken for 1 epoch: 251.39 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 2.6673 Accuracy 0.6447\n",
      "Epoch 20 Batch 200 Loss 2.7101 Accuracy 0.6304\n",
      "Epoch 20 Batch 400 Loss 2.7144 Accuracy 0.6284\n",
      "Epoch 20 Batch 600 Loss 2.7069 Accuracy 0.6302\n",
      "Epoch 20 Batch 800 Loss 2.7060 Accuracy 0.6311\n",
      "Epoch 20 Batch 1000 Loss 2.7054 Accuracy 0.6314\n",
      "Epoch 20 Batch 1200 Loss 2.7057 Accuracy 0.6315\n",
      "Epoch 20 Batch 1400 Loss 2.7056 Accuracy 0.6316\n",
      "Epoch 20 Batch 1600 Loss 2.7076 Accuracy 0.6312\n",
      "Epoch 20 Batch 1800 Loss 2.7091 Accuracy 0.6312\n",
      "Epoch 20 Batch 2000 Loss 2.7113 Accuracy 0.6309\n",
      "Epoch 20 Batch 2200 Loss 2.7126 Accuracy 0.6306\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-20\n",
      "Epoch 20 Loss 2.7131 Accuracy 0.6306\n",
      "Validation loss: 3.4329 Validation accuracy 0.5218\n",
      "Time taken for 1 epoch: 251.10 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 2.7003 Accuracy 0.6247\n",
      "Epoch 21 Batch 200 Loss 2.6701 Accuracy 0.6375\n",
      "Epoch 21 Batch 400 Loss 2.6723 Accuracy 0.6364\n",
      "Epoch 21 Batch 600 Loss 2.6625 Accuracy 0.6388\n",
      "Epoch 21 Batch 800 Loss 2.6649 Accuracy 0.6389\n",
      "Epoch 21 Batch 1000 Loss 2.6644 Accuracy 0.6391\n",
      "Epoch 21 Batch 1200 Loss 2.6665 Accuracy 0.6391\n",
      "Epoch 21 Batch 1400 Loss 2.6691 Accuracy 0.6385\n",
      "Epoch 21 Batch 1600 Loss 2.6716 Accuracy 0.6382\n",
      "Epoch 21 Batch 1800 Loss 2.6716 Accuracy 0.6382\n",
      "Epoch 21 Batch 2000 Loss 2.6722 Accuracy 0.6382\n",
      "Epoch 21 Batch 2200 Loss 2.6741 Accuracy 0.6378\n",
      "Saving checkpoint for epoch 21 at ./checkpoints/train/ckpt-21\n",
      "Epoch 21 Loss 2.6746 Accuracy 0.6378\n",
      "Validation loss: 3.4445 Validation accuracy 0.5188\n",
      "Time taken for 1 epoch: 251.11 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 2.7378 Accuracy 0.6210\n",
      "Epoch 22 Batch 200 Loss 2.6389 Accuracy 0.6431\n",
      "Epoch 22 Batch 400 Loss 2.6395 Accuracy 0.6434\n",
      "Epoch 22 Batch 600 Loss 2.6321 Accuracy 0.6446\n",
      "Epoch 22 Batch 800 Loss 2.6310 Accuracy 0.6452\n",
      "Epoch 22 Batch 1000 Loss 2.6306 Accuracy 0.6452\n",
      "Epoch 22 Batch 1200 Loss 2.6326 Accuracy 0.6447\n",
      "Epoch 22 Batch 1400 Loss 2.6348 Accuracy 0.6443\n",
      "Epoch 22 Batch 1600 Loss 2.6367 Accuracy 0.6442\n",
      "Epoch 22 Batch 1800 Loss 2.6363 Accuracy 0.6443\n",
      "Epoch 22 Batch 2000 Loss 2.6384 Accuracy 0.6440\n",
      "Epoch 22 Batch 2200 Loss 2.6388 Accuracy 0.6441\n",
      "Saving checkpoint for epoch 22 at ./checkpoints/train/ckpt-22\n",
      "Epoch 22 Loss 2.6402 Accuracy 0.6439\n",
      "Validation loss: 3.4277 Validation accuracy 0.5228\n",
      "Time taken for 1 epoch: 250.93 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 2.6596 Accuracy 0.6494\n",
      "Epoch 23 Batch 200 Loss 2.6037 Accuracy 0.6498\n",
      "Epoch 23 Batch 400 Loss 2.6005 Accuracy 0.6508\n",
      "Epoch 23 Batch 600 Loss 2.5938 Accuracy 0.6522\n",
      "Epoch 23 Batch 800 Loss 2.5925 Accuracy 0.6526\n",
      "Epoch 23 Batch 1000 Loss 2.5968 Accuracy 0.6520\n",
      "Epoch 23 Batch 1200 Loss 2.6014 Accuracy 0.6508\n",
      "Epoch 23 Batch 1400 Loss 2.6034 Accuracy 0.6505\n",
      "Epoch 23 Batch 1600 Loss 2.6053 Accuracy 0.6503\n",
      "Epoch 23 Batch 1800 Loss 2.6071 Accuracy 0.6501\n",
      "Epoch 23 Batch 2000 Loss 2.6080 Accuracy 0.6502\n",
      "Epoch 23 Batch 2200 Loss 2.6095 Accuracy 0.6498\n",
      "Saving checkpoint for epoch 23 at ./checkpoints/train/ckpt-23\n",
      "Epoch 23 Loss 2.6093 Accuracy 0.6498\n",
      "Validation loss: 3.4349 Validation accuracy 0.5210\n",
      "Time taken for 1 epoch: 248.86 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 2.5643 Accuracy 0.6379\n",
      "Epoch 24 Batch 200 Loss 2.5710 Accuracy 0.6560\n",
      "Epoch 24 Batch 400 Loss 2.5701 Accuracy 0.6559\n",
      "Epoch 24 Batch 600 Loss 2.5649 Accuracy 0.6574\n",
      "Epoch 24 Batch 800 Loss 2.5680 Accuracy 0.6568\n",
      "Epoch 24 Batch 1000 Loss 2.5695 Accuracy 0.6566\n",
      "Epoch 24 Batch 1200 Loss 2.5726 Accuracy 0.6563\n",
      "Epoch 24 Batch 1400 Loss 2.5730 Accuracy 0.6565\n",
      "Epoch 24 Batch 1600 Loss 2.5740 Accuracy 0.6564\n",
      "Epoch 24 Batch 1800 Loss 2.5748 Accuracy 0.6561\n",
      "Epoch 24 Batch 2000 Loss 2.5764 Accuracy 0.6559\n",
      "Epoch 24 Batch 2200 Loss 2.5781 Accuracy 0.6556\n",
      "Saving checkpoint for epoch 24 at ./checkpoints/train/ckpt-24\n",
      "Epoch 24 Loss 2.5800 Accuracy 0.6553\n",
      "Validation loss: 3.4450 Validation accuracy 0.5206\n",
      "Time taken for 1 epoch: 249.36 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 2.4351 Accuracy 0.6893\n",
      "Epoch 25 Batch 200 Loss 2.5523 Accuracy 0.6586\n",
      "Epoch 25 Batch 400 Loss 2.5482 Accuracy 0.6596\n",
      "Epoch 25 Batch 600 Loss 2.5409 Accuracy 0.6614\n",
      "Epoch 25 Batch 800 Loss 2.5384 Accuracy 0.6624\n",
      "Epoch 25 Batch 1000 Loss 2.5407 Accuracy 0.6623\n",
      "Epoch 25 Batch 1200 Loss 2.5422 Accuracy 0.6621\n",
      "Epoch 25 Batch 1400 Loss 2.5435 Accuracy 0.6621\n",
      "Epoch 25 Batch 1600 Loss 2.5466 Accuracy 0.6615\n",
      "Epoch 25 Batch 1800 Loss 2.5480 Accuracy 0.6613\n",
      "Epoch 25 Batch 2000 Loss 2.5502 Accuracy 0.6610\n",
      "Epoch 25 Batch 2200 Loss 2.5512 Accuracy 0.6610\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/train/ckpt-25\n",
      "Epoch 25 Loss 2.5527 Accuracy 0.6607\n",
      "Validation loss: 3.4537 Validation accuracy 0.5208\n",
      "Time taken for 1 epoch: 248.17 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "\n",
    "  # inp -> english, tar -> vietnamese\n",
    "  for (batch, (inp, tar)) in enumerate(train_batches):\n",
    "    train_step(inp, tar)\n",
    "    if batch % 200 == 0:\n",
    "      print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "  \n",
    "  validation_loss.reset_states()\n",
    "  validation_accuracy.reset_states()\n",
    "\n",
    "  for (batch, (inp, tar)) in enumerate(validation_batches):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    predictions, _ = transformer(inp, tar_inp,\n",
    "                                 True,\n",
    "                                 enc_padding_mask,\n",
    "                                 combined_mask,\n",
    "                                 dec_padding_mask)\n",
    "    val_loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    validation_loss(val_loss)\n",
    "    validation_accuracy(accuracy_function(tar_real, predictions))\n",
    "\n",
    "  if (epoch + 1) % 1 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
    "  \n",
    "\n",
    "  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "  print(f'Validation loss: {validation_loss.result():.4f} Validation accuracy {validation_accuracy.result():.4f}')\n",
    "\n",
    "  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "machine_translation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
